{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0327caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tkinter as tk\n",
    "from tkinter import messagebox, filedialog, Menu, simpledialog, Scrollbar\n",
    "import pandas as pd\n",
    "import os  # Import the os m\n",
    "\n",
    "def get_user_file():\n",
    "    # Can update the global input_directory to call back later\n",
    "    # global input_directory\n",
    "\n",
    "\n",
    "    # Default filetype fire\n",
    "    files_types = [('TXT',\"*.txt *.TXT\"), \n",
    "                   ('CSV',\"*.csv *.CSV\")]    \n",
    "    \n",
    "    # Ask user to select file\n",
    "    f_path = filedialog.askopenfilename(title=\"Choose trace file\", filetypes=files_types)\n",
    "\n",
    "    # Catch no file selected\n",
    "    if len(f_path) == 0:\n",
    "        messagebox.showinfo(\"Error\", \"No file chosen. Try again.\")\n",
    "        return None, None\n",
    "\n",
    "    return f_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "5070d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_burrow(val: str) -> str:\n",
    "    s = str(val)\n",
    "\n",
    "    # Remove file extension if present (.txt, .csv, any case)\n",
    "    for ext in (\".txt\", \".csv\"):\n",
    "        if s.lower().endswith(ext):\n",
    "            s = s[: -len(ext)]\n",
    "            break\n",
    "    # take the last 3 of what is left\n",
    "    s = s[-3:]\n",
    "\n",
    "    # deal with less than 3 digits\n",
    "    if s.startswith(\"_\"):       # e.g., \"_31\"\n",
    "        s = s[1:]               # drop the leading underscore → \"31\"\n",
    "    elif \"_\" in s:              # e.g., \"5_3\"\n",
    "        s = s.split(\"_\")[-1]    # take part after underscore → \"3\"\n",
    "\n",
    "    # Return only if it's digits and padded to 3 places\n",
    "    return s.zfill(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b9387f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PIT_ID  Rdr          PIT_DateTime\n",
      "0  0620000555    1   06/19/2025 16:59:40\n",
      "1  0620000555    1   06/19/2025 16:59:41\n",
      "2  0620000555    1   06/19/2025 16:59:42\n",
      "3  0620000555    1   06/19/2025 16:59:44\n",
      "4  0620000555    1   06/19/2025 16:59:45\n",
      "5  0620000555    1   06/20/2025 09:45:50\n",
      "6  0620000555    1   06/20/2025 09:45:51\n",
      "7  0620000555    1   06/20/2025 16:18:26\n",
      "8  0620000555    1   06/20/2025 16:18:27\n",
      "9  0620000AFA    1   06/20/2025 23:22:43\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path_RFID = \"/Users/bobmauck/devel/Combo_App/Example_Data/RF_06_24_2025_933.TXT\"   # get_user_file()# Get user file path\n",
    "# return none\n",
    "# filename = os.path.basename(file_path_RFID)\n",
    "# if filename.startswith('RF'):\n",
    "# Read CSV without assuming headers\n",
    "df_RFID = pd.read_csv(file_path_RFID, delimiter=',', header=None, names=['PIT_ID', 'Rdr', 'PIT_DateTime'], \n",
    "                        on_bad_lines='warn')\n",
    "print(df_RFID.head(10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "81906263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   File  Trace_Segment_Num             DateTime  Wt_Min_Slope\n",
      "0   DL_06_24_2025_3.TXT                  1  2025-06-24 16:18:32         50.00\n",
      "1   DL_06_24_2025_3.TXT                  2  2025-06-24 16:18:48         98.71\n",
      "2   DL_06_24_2025_3.TXT                  3  2025-06-25 03:00:47         42.88\n",
      "3   DL_06_24_2025_3.TXT                  4  2025-06-25 08:29:24         49.97\n",
      "4   DL_06_24_2025_3.TXT                  5  2025-06-25 08:29:45         99.78\n",
      "5  DL_06_24_2025_59.TXT                  1  2025-06-24 14:38:55         50.14\n",
      "6  DL_06_24_2025_59.TXT                  2  2025-06-24 14:39:11         99.96\n",
      "7  DL_06_24_2025_59.TXT                  3  2025-06-25 07:52:29         50.21\n",
      "8  DL_06_24_2025_59.TXT                  4  2025-06-25 07:52:45        100.03\n",
      "9  DL_06_24_2025_87.TXT                  1  2000-01-01 00:00:00         50.17\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path_MOM = \"/Users/bobmauck/devel/Combo_App/Example_Data/Bird_Weight_Files_June_24th.txt\"\n",
    "# MOM_Names = ['File','Trace_Segment_Num','DateTime','stop','start','Wt_Mean','Wt_MeanG','Wt_Median','Wt_Min_Slope','Wt_Liam','Slope','Min_Slope','d_nXSTD','d_STD','d_PctAbove','d_PctBelow','d_PctAboveX','Type','Method','notes']\n",
    "cols_to_import = ['File', 'Trace_Segment_Num', 'DateTime', 'Wt_Min_Slope']\n",
    "\n",
    "df_MOM = pd.read_csv(\n",
    "                        file_path_MOM, \n",
    "                        delimiter=',', \n",
    "                        usecols=cols_to_import,\n",
    "                        header=0,\n",
    "                        on_bad_lines='warn')\n",
    "print(df_MOM.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "73c588a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PIT_ID</th>\n",
       "      <th>Rdr</th>\n",
       "      <th>PIT_DateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>0620000AFA</td>\n",
       "      <td>1</td>\n",
       "      <td>06/25/2025 01:06:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>0620000AFA</td>\n",
       "      <td>1</td>\n",
       "      <td>06/25/2025 01:06:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PIT_ID  Rdr          PIT_DateTime\n",
       "1044  0620000AFA    1   06/25/2025 01:06:31\n",
       "1045  0620000AFA    1   06/25/2025 01:06:32"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RFID.tail(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6947ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Trace_Segment_Num</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Wt_Min_Slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>DL_06_24_2025_933.TXT</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-24 16:21:12</td>\n",
       "      <td>50.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>DL_06_24_2025_933.TXT</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-06-24 16:21:28</td>\n",
       "      <td>99.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>DL_06_24_2025_933.TXT</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-06-24 23:29:14</td>\n",
       "      <td>55.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>DL_06_24_2025_933.TXT</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-06-25 00:08:11</td>\n",
       "      <td>47.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>DL_06_24_2025_933.TXT</td>\n",
       "      <td>7</td>\n",
       "      <td>2025-06-25 08:27:40</td>\n",
       "      <td>50.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>DL_06_24_2025_933.TXT</td>\n",
       "      <td>8</td>\n",
       "      <td>2025-06-25 08:28:01</td>\n",
       "      <td>100.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      File  Trace_Segment_Num             DateTime  \\\n",
       "109  DL_06_24_2025_933.TXT                  1  2025-06-24 16:21:12   \n",
       "110  DL_06_24_2025_933.TXT                  2  2025-06-24 16:21:28   \n",
       "111  DL_06_24_2025_933.TXT                  4  2025-06-24 23:29:14   \n",
       "112  DL_06_24_2025_933.TXT                  5  2025-06-25 00:08:11   \n",
       "113  DL_06_24_2025_933.TXT                  7  2025-06-25 08:27:40   \n",
       "114  DL_06_24_2025_933.TXT                  8  2025-06-25 08:28:01   \n",
       "\n",
       "     Wt_Min_Slope  \n",
       "109         50.19  \n",
       "110         99.96  \n",
       "111         55.28  \n",
       "112         47.92  \n",
       "113         50.22  \n",
       "114        100.05  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset = df_MOM[df_MOM['File'].str.endswith('_933.TXT', na=False)].copy()\n",
    "df_subset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0314734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # Import the os m\n",
    "\n",
    "def get_MOM_data(burr):\n",
    "    file_path_MOM = \"/Users/bobmauck/devel/Combo_App/Example_Data/Bird_Weight_Files_June_24th.txt\"\n",
    "    # MOM_Names = ['File','Trace_Segment_Num','DateTime','stop','start','Wt_Mean','Wt_MeanG','Wt_Median','Wt_Min_Slope','Wt_Liam','Slope','Min_Slope','d_nXSTD','d_STD','d_PctAbove','d_PctBelow','d_PctAboveX','Type','Method','notes']\n",
    "    cols_to_import = ['File', 'Trace_Segment_Num', 'DateTime', 'Wt_Min_Slope']\n",
    "\n",
    "    df_MOM = pd.read_csv(\n",
    "                            file_path_MOM, \n",
    "                            delimiter=',', \n",
    "                            usecols=cols_to_import,\n",
    "                            header=0,\n",
    "                            on_bad_lines='warn')\n",
    "    # print(df_MOM.head(10))\n",
    "\n",
    "    df_subset = df_MOM[df_MOM['File'].str.endswith(burr, na=False)].copy()\n",
    "    # df_subset.head(10)\n",
    "\n",
    "    return df_subset\n",
    "\n",
    "def get_RFID_data():\n",
    "    file_path_RFID = \"/Users/bobmauck/devel/Combo_App/Example_Data/RF_06_24_2025_933.TXT\"   # get_user_file()# Get user file path\n",
    "    # return none\n",
    "    rf_filename = os.path.basename(file_path_RFID)\n",
    "    # if filename.startswith('RF'):\n",
    "    # Read CSV without assuming headers\n",
    "    df_RFID = pd.read_csv(file_path_RFID, delimiter=',', header=None, names=['PIT_ID', 'Rdr', 'PIT_DateTime'], \n",
    "                            on_bad_lines='warn')\n",
    "    df_subsetRFID = df_RFID[~df_RFID['PIT_ID'].astype(str).str.endswith('000555', na=False)].copy()\n",
    "    df_subsetRFID['RF_File'] = rf_filename\n",
    "    print(rf_filename)\n",
    "\n",
    "    return df_subsetRFID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b19f0b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF_06_24_2025_933.TXT\n"
     ]
    }
   ],
   "source": [
    "df_MOM = get_MOM_data('_933.TXT')\n",
    "df_RFID = get_RFID_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f44c26a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "be823749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.tail of                      MOM_File Segment            DateTime      Wt Burrow  \\\n",
      "0    DL_06_21-22_2025_235.TXT       3 2000-01-01 00:00:00   50.27    235   \n",
      "1    DL_06_21-22_2025_235.TXT       2 2000-01-01 00:00:00   99.99    235   \n",
      "2    DL_06_21-22_2025_235.TXT       1 2000-01-01 00:00:00   50.18    235   \n",
      "3     DL_06_21-22_2025_87.TXT       4 2000-01-01 00:00:00  100.54    _87   \n",
      "4     DL_06_21-22_2025_87.TXT       3 2000-01-01 00:00:00   50.53    _87   \n",
      "..                        ...     ...                 ...     ...    ...   \n",
      "128      DL_06_24_2025_97.TXT       4 2025-06-25 00:33:32   47.20    _97   \n",
      "129     DL_06_24_2025_952.TXT       8 2025-06-25 02:27:47   43.51    952   \n",
      "130     DL_06_24_2025_952.TXT       9 2025-06-25 02:51:10   40.20    952   \n",
      "131       DL_06_24_2025_3.TXT       3 2025-06-25 03:00:47   42.88    5_3   \n",
      "132     DL_06_24_2025_230.TXT       3 2025-06-25 03:40:47   30.65    230   \n",
      "\n",
      "     n_Matches RF_File  Rdr RFID  \n",
      "0            0     NaN  NaN  NaN  \n",
      "1            0     NaN  NaN  NaN  \n",
      "2            0     NaN  NaN  NaN  \n",
      "3            0     NaN  NaN  NaN  \n",
      "4            0     NaN  NaN  NaN  \n",
      "..         ...     ...  ...  ...  \n",
      "128          0     NaN  NaN  NaN  \n",
      "129          0     NaN  NaN  NaN  \n",
      "130          0     NaN  NaN  NaN  \n",
      "131          0     NaN  NaN  NaN  \n",
      "132          0     NaN  NaN  NaN  \n",
      "\n",
      "[133 rows x 9 columns]>\n"
     ]
    }
   ],
   "source": [
    "df_MOM_with_counts = add_match_counts_shifted(df_WtFiles, df_RFID, window=\"5min\")\n",
    "print(df_MOM_with_counts.tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "835e9cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def get_All_Mom_data(\n",
    "    folder: str = \"/Users/bobmauck/devel/Combo_App/Example_Data\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load all files in 'folder' that start with 'Bird_Weight_' and end with '.txt' (case-insensitive),\n",
    "    combine them into a single DataFrame, remove duplicates, and return it.\n",
    "    Adds a 'Burrow' column extracted from the last 3 characters of the 'File' column.\n",
    "    Renames:\n",
    "        'File' -> 'MOM_File'\n",
    "        'Trace_Segment_Num' -> 'Segment'\n",
    "    \"\"\"\n",
    "    cols_to_import = ['File', 'Trace_Segment_Num', 'DateTime', 'Wt_Min_Slope']\n",
    "\n",
    "    # Debug info\n",
    "    # print(f\"Looking in folder: {folder}\")\n",
    "    try:\n",
    "        files_in_folder = os.listdir(folder)\n",
    "        # print(\"Files in folder:\")\n",
    "        for f in files_in_folder:\n",
    "            pass # print(f\"  {f}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Folder not found: {folder}\")\n",
    "        return pd.DataFrame(columns=['MOM_File', 'Segment', 'DateTime', 'Wt_Min_Slope', 'Burrow'])\n",
    "\n",
    "    all_dfs = []\n",
    "\n",
    "    # Loop through matching files\n",
    "    for filename in files_in_folder:\n",
    "        if filename.lower().startswith(\"bird_weight_\") and filename.lower().endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            try:\n",
    "                df_temp = pd.read_csv(\n",
    "                    file_path,\n",
    "                    delimiter=',',\n",
    "                    usecols=cols_to_import,\n",
    "                    header=0,\n",
    "                    on_bad_lines='warn'\n",
    "                )\n",
    "                # Extract burrow code from 'File' column\n",
    "                #df_temp['Burrow'] = df_temp['File'].astype(str).str[-7:-4]\n",
    "                df_temp[\"Burrow\"] = df_temp[\"File\"].astype(str).apply(clean_burrow)\n",
    "                all_dfs.append(df_temp)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "    if not all_dfs:\n",
    "        print(\"No matching files found.\")\n",
    "        return pd.DataFrame(columns=['MOM_File', 'Segment', 'DateTime', 'Wt_Min_Slope', 'Burrow'])\n",
    "\n",
    "    # Combine and drop duplicates\n",
    "    df_MOM = pd.concat(all_dfs, ignore_index=True).drop_duplicates()\n",
    "\n",
    "    # Rename columns\n",
    "    df_MOM.rename(columns={'File': 'MOM_File', 'Trace_Segment_Num': 'Segment'}, inplace=True)\n",
    "\n",
    "    return df_MOM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "1ea19a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight files loaded successfully.\n",
      "               MOM_File Segment             DateTime  Wt_Min_Slope Burrow\n",
      "0   DL_06_25_2025_3.TXT       1  2025-06-25 16:08:04         50.20    003\n",
      "1   DL_06_25_2025_3.TXT       2  2025-06-25 16:08:25        100.07    003\n",
      "2   DL_06_25_2025_3.TXT       3  2025-06-26 08:29:28         50.01    003\n",
      "3   DL_06_25_2025_3.TXT       4  2025-06-26 08:29:49         99.98    003\n",
      "4  DL_06_25_2025_59.TXT       1  2025-06-25 14:53:56         50.20    059\n",
      "5  DL_06_25_2025_59.TXT       2  2025-06-25 14:54:17        100.00    059\n",
      "6  DL_06_25_2025_59.TXT       3  2025-06-26 07:40:54         50.38    059\n",
      "7  DL_06_25_2025_59.TXT       4  2025-06-26 07:41:15        100.38    059\n",
      "8  DL_06_25_2025_87.TXT       1  2000-01-01 00:00:00         50.21    087\n",
      "9  DL_06_25_2025_87.TXT       2  2000-01-01 00:00:00         99.99    087\n"
     ]
    }
   ],
   "source": [
    "df_WtFiles = get_All_Mom_data()\n",
    "if df_WtFiles.empty:    \n",
    "    print(\"No weight files found.\")\n",
    "else:\n",
    "    print(\"Weight files loaded successfully.\")\n",
    "    print(df_WtFiles.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "bf679ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_All_RFID_data(\n",
    "    folder: str = \"/Users/bobmauck/devel/Combo_App/Example_Data\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load all files in 'folder' that start with 'RF' and end with '.txt',\n",
    "    combine them into a single DataFrame, remove duplicates, and return it.\n",
    "    Assumes the files have NO header row and uses:\n",
    "        ['PIT_ID', 'Rdr', 'PIT_DateTime']\n",
    "    as the column names.\n",
    "    \"\"\"\n",
    "    cols_to_import = ['PIT_ID', 'Rdr', 'PIT_DateTime']\n",
    "\n",
    "    # Debug info\n",
    "    # print(f\"Looking in folder: {folder}\")\n",
    "    try:\n",
    "        files_in_folder = os.listdir(folder)\n",
    "        # print(\"Files in folder:\")\n",
    "        for f in files_in_folder:\n",
    "            #print(f\"  {f}\")\n",
    "            pass  # Uncomment to print files in folder\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Folder not found: {folder}\")\n",
    "        return pd.DataFrame(columns=cols_to_import)\n",
    "\n",
    "    all_dfs = []\n",
    "\n",
    "    # Loop through matching files\n",
    "    for filename in files_in_folder:\n",
    "        if filename.lower().startswith(\"rf\") and filename.lower().endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            try:\n",
    "                df_temp = pd.read_csv(\n",
    "                    file_path,\n",
    "                    delimiter=',',\n",
    "                    header=None,                # No header in file\n",
    "                    names=cols_to_import,       # Assign column names\n",
    "                    usecols=[0, 1, 2],          # Only first 3 columns\n",
    "                    on_bad_lines='warn'\n",
    "                )\n",
    "                # Add the filename column\n",
    "                df_temp['RF_File'] = filename\n",
    "                df_temp['Burrow'] = df_temp['RF_File'].astype(str).str[-7:-4]\n",
    "                df_temp[\"Burrow\"] = df_temp[\"Burrow\"].astype(str).apply(clean_burrow)\n",
    "                \n",
    "                all_dfs.append(df_temp)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "    if not all_dfs:\n",
    "        print(\"No matching files found.\")\n",
    "        return pd.DataFrame(columns=cols_to_import)\n",
    "\n",
    "    # Combine and drop duplicates\n",
    "    df_RFID = pd.concat(all_dfs, ignore_index=True).drop_duplicates()\n",
    "\n",
    "    return df_RFID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "40a2896b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PIT_ID  Rdr          PIT_DateTime                RF_File Burrow\n",
      "0  062000057B    1   05/30/2025 11:54:17  RF_06_16_2025_352.TXT    352\n",
      "1  062000057B    2   05/30/2025 11:54:20  RF_06_16_2025_352.TXT    352\n",
      "2  0620000555    1   06/11/2025 09:02:47  RF_06_16_2025_352.TXT    352\n",
      "3  0620000555    1   06/11/2025 09:02:48  RF_06_16_2025_352.TXT    352\n",
      "4  0620000555    1   06/11/2025 09:02:49  RF_06_16_2025_352.TXT    352\n"
     ]
    }
   ],
   "source": [
    "df_rfid = get_All_RFID_data(\"/Users/bobmauck/devel/Combo_App/Example_Data\")\n",
    "print(df_rfid.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "88732b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def join_MOM_RFID(\n",
    "    df_MOM: pd.DataFrame,\n",
    "    df_RFID: pd.DataFrame,\n",
    "    window: str = \"2min\",\n",
    "    mom_time_col: str = \"DateTime\",\n",
    "    rfid_time_col: str | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each MOM row, count RFID reads within ±`window` (RFID times shifted back 1h),\n",
    "    but only against RFID rows with the same 'Burrow'. Keep rows with time-of-day\n",
    "    <07:00 or >20:00 and n_Matches > 0. Attach closest RFID's PIT_ID ('RFID') and 'Rdr'.\n",
    "    Accumulates results across ALL burrows.\n",
    "    \"\"\"\n",
    "    tol = pd.to_timedelta(window)\n",
    "\n",
    "    # Pick RFID datetime column if not provided\n",
    "    if rfid_time_col is None:\n",
    "        if \"PIT_DateTime\" in df_RFID.columns:\n",
    "            rfid_time_col = \"PIT_DateTime\"\n",
    "        elif \"DateTime\" in df_RFID.columns:\n",
    "            rfid_time_col = \"DateTime\"\n",
    "        else:\n",
    "            raise KeyError(\"No RFID datetime column found (need 'PIT_DateTime' or 'DateTime').\")\n",
    "\n",
    "    mom = df_MOM.copy()\n",
    "    rfid = df_RFID.copy()\n",
    "\n",
    "    # Require Burrow on both sides\n",
    "    if \"Burrow\" not in mom.columns or \"Burrow\" not in rfid.columns:\n",
    "        raise KeyError(\"Both df_MOM and df_RFID must contain a 'Burrow' column.\")\n",
    "\n",
    "    # Normalize types\n",
    "    mom[\"Burrow\"] = mom[\"Burrow\"].astype(str)\n",
    "    rfid[\"Burrow\"] = rfid[\"Burrow\"].astype(str)\n",
    "\n",
    "    # Parse datetimes\n",
    "    mom[mom_time_col] = pd.to_datetime(mom[mom_time_col], errors=\"coerce\")\n",
    "    rfid[rfid_time_col] = pd.to_datetime(rfid[rfid_time_col], errors=\"coerce\")\n",
    "\n",
    "    # Shift RFID times back 1 hour\n",
    "    rfid[\"_join_time\"] = rfid[rfid_time_col] - pd.Timedelta(hours=1)\n",
    "\n",
    "    # Precompute per-burrow sorted arrays for counting\n",
    "    rfid_valid = rfid.dropna(subset=[\"_join_time\"])\n",
    "    rfid_groups = {\n",
    "        b: grp[\"_join_time\"].sort_values().to_numpy(dtype=\"datetime64[ns]\")\n",
    "        for b, grp in rfid_valid.groupby(\"Burrow\", sort=False)\n",
    "    }\n",
    "\n",
    "    # Count matches for each MOM row in its Burrow\n",
    "    counts = np.zeros(len(mom), dtype=int)\n",
    "    tol_ns = np.int64(pd.to_timedelta(tol).value)\n",
    "    mom_times = mom[mom_time_col].to_numpy(dtype=\"datetime64[ns]\")\n",
    "    mom_bur = mom[\"Burrow\"].to_numpy()\n",
    "\n",
    "    for i, (t, b) in enumerate(zip(mom_times, mom_bur)):\n",
    "        if np.isnat(t) or b not in rfid_groups:\n",
    "            continue\n",
    "        arr = rfid_groups[b]\n",
    "        low = (t.astype(\"int64\") - tol_ns).view(\"datetime64[ns]\")\n",
    "        high = (t.astype(\"int64\") + tol_ns).view(\"datetime64[ns]\")\n",
    "        left = np.searchsorted(arr, low, side=\"left\")\n",
    "        right = np.searchsorted(arr, high, side=\"right\")\n",
    "        counts[i] = right - left\n",
    "\n",
    "    mom[\"n_Matches\"] = counts\n",
    "\n",
    "    # Filter: <07:00 or >20:00 AND n_Matches > 0\n",
    "    valid_time = mom[mom_time_col].notna()\n",
    "    hours_mask = valid_time & ((mom[mom_time_col].dt.hour < 7) | (mom[mom_time_col].dt.hour > 20))\n",
    "    matches_mask = mom[\"n_Matches\"] > 0\n",
    "    reduced = mom.loc[hours_mask & matches_mask].copy()\n",
    "\n",
    "    if reduced.empty:\n",
    "        reduced[\"RFID\"] = pd.Series(dtype=object)\n",
    "        reduced[\"Rdr\"] = pd.Series(dtype=object)\n",
    "        return reduced\n",
    "\n",
    "    # --- Accumulate per-burrow merges ---\n",
    "    pieces = []\n",
    "    for b, mom_g in reduced.groupby(\"Burrow\", sort=False):\n",
    "        rfid_g = rfid_valid[rfid_valid[\"Burrow\"] == b]\n",
    "        if rfid_g.empty:\n",
    "            # no RFID for this burrow; keep structure, but NaNs for RFID/Rdr\n",
    "            tmp = mom_g.copy()\n",
    "            tmp[\"RFID\"] = pd.NA\n",
    "            tmp[\"Rdr\"] = pd.NA\n",
    "            pieces.append(tmp)\n",
    "            continue\n",
    "\n",
    "        mom_g = mom_g.dropna(subset=[mom_time_col]).sort_values(mom_time_col, kind=\"mergesort\")\n",
    "        rfid_g = rfid_g.sort_values(\"_join_time\", kind=\"mergesort\")\n",
    "\n",
    "        merged_g = pd.merge_asof(\n",
    "            mom_g,\n",
    "            rfid_g[[\"_join_time\", \"PIT_ID\", \"Rdr\", \"RF_File\", \"Burrow\"]],\n",
    "            left_on=mom_time_col,\n",
    "            right_on=\"_join_time\",\n",
    "            direction=\"nearest\",\n",
    "            tolerance=tol,\n",
    "        )\n",
    "        merged_g[\"RFID\"] = merged_g[\"PIT_ID\"]\n",
    "        # merged_g = merged_g.drop(columns=[\"PIT_ID\", \"Burrow_x\", \"Burrow_y\"], errors=\"ignore\")\n",
    "        pieces.append(merged_g)\n",
    "\n",
    "    out = pd.concat(pieces, ignore_index=False).sort_index(kind=\"mergesort\")\n",
    "\n",
    "    # Optional legacy renames if present\n",
    "    rename_map = {}\n",
    "    if \"Trace_Segment_Num\" in out.columns:\n",
    "        rename_map[\"Trace_Segment_Num\"] = \"Segmnt\"\n",
    "    if \"Wt_Min_Slope\" in out.columns:\n",
    "        rename_map[\"Wt_Min_Slope\"] = \"Wt\"\n",
    "    if \"_join_time\" in out.columns:\n",
    "        rename_map[\"_join_time\"] = \"Closest_RFID_Time\"\n",
    "    if \"n_Matches\" in out.columns:\n",
    "        rename_map[\"n_Matches\"] = \"N\"\n",
    "    if \"DateTime\" in out.columns:\n",
    "        rename_map[\"DateTime\"] = \"MOM_Time\"\n",
    "    if \"Burrow_x\" in out.columns:\n",
    "        rename_map[\"Burrow_x\"] = \"Burrow\"\n",
    "    if rename_map:\n",
    "        out = out.rename(columns=rename_map)\n",
    "    \n",
    "    # sort by \n",
    "    # Sort using Burrow while it's still present\n",
    "    out = out.sort_values([\"Burrow\", \"MOM_Time\"], kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "    # Now drop the extra columns\n",
    "    out = out.drop(columns=[\"PIT_ID\", \"Burrow_y\"], errors=\"ignore\")\n",
    "\n",
    "    # Order output columns\n",
    "    desired_order = [\"Burrow\", \"MOM_File\", \"MOM_Time\", \"Segment\", \"Wt\", \"RFID\", \"N\", \"Rdr\", \"Closest_RFID_Time\", \"RF_File\"]\n",
    "    out = out[[col for col in desired_order if col in out.columns]]\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "c266561c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Burrow               MOM_File            MOM_Time Segment     Wt  \\\n",
      "0     219  DL_06_24_2025_219.TXT 2025-06-24 23:37:50       4  50.43   \n",
      "1     219  DL_06_24_2025_219.TXT 2025-06-25 00:01:55       5  37.01   \n",
      "2     230  DL_06_22_2025_230.TXT 2025-06-23 00:20:12       5  50.51   \n",
      "3     230  DL_06_22_2025_230.TXT 2025-06-23 00:20:38       6  48.33   \n",
      "4     230  DL_06_24_2025_230.TXT 2025-06-25 03:40:47       3  30.65   \n",
      "5     933  DL_06_22_2025_933.TXT 2025-06-22 22:01:52       3  53.25   \n",
      "6     933  DL_06_22_2025_933.TXT 2025-06-22 22:25:23       4  49.68   \n",
      "7     933  DL_06_24_2025_933.TXT 2025-06-24 23:29:14       4  55.28   \n",
      "8     933  DL_06_24_2025_933.TXT 2025-06-25 00:08:11       5  47.92   \n",
      "9     _97   DL_06_24_2025_97.TXT 2025-06-25 00:12:12       3  52.73   \n",
      "10    _97   DL_06_24_2025_97.TXT 2025-06-25 00:33:32       4  47.20   \n",
      "\n",
      "          RFID    N  Rdr   Closest_RFID_Time                   RF_File  \n",
      "0   0620000CBC   28    2 2025-06-24 23:36:17     RF_06_25_2025_219.TXT  \n",
      "1   0620000B69   54    2 2025-06-25 00:00:17     RF_06_25_2025_219.TXT  \n",
      "2   0620000BF9   90    1 2025-06-23 00:19:09     RF_06_23_2025_230.TXT  \n",
      "3   0620000BF9   86    1 2025-06-23 00:19:09     RF_06_23_2025_230.TXT  \n",
      "4   0620000BF9  101    2 2025-06-25 03:39:31     RF_06_24_2025_230.TXT  \n",
      "5   0620000AFA   15    2 2025-06-22 22:00:23  RF_06_21-22_2025_933.TXT  \n",
      "6   0620000C8F  285    1 2025-06-22 22:24:06  RF_06_21-22_2025_933.TXT  \n",
      "7   0620000C8F    9    2 2025-06-24 23:27:38     RF_06_24_2025_933.TXT  \n",
      "8   0620000AFA   80    1 2025-06-25 00:06:32     RF_06_24_2025_933.TXT  \n",
      "9   0620000AF4   16    2 2025-06-25 00:10:50      RF_06_24_2025_97.TXT  \n",
      "10  0620000C84  166    1 2025-06-25 00:32:39      RF_06_24_2025_97.TXT  \n"
     ]
    }
   ],
   "source": [
    "df_MOM_with_counts = join_MOM_RFID(df_WtFiles, df_rfid, window=\"3min\")\n",
    "print(df_MOM_with_counts.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "a18d09bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def join_MOM_RFID(\n",
    "    df_MOM: pd.DataFrame,\n",
    "    df_RFID: pd.DataFrame,\n",
    "    window: str = \"2min\",\n",
    "    mom_time_col: str = \"DateTime\",\n",
    "    rfid_time_col: str | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each MOM row, count RFID reads within ±`window` (first try RFID shifted -1h).\n",
    "    If a MOM row has 0 matches under the -1h shift, retry the search with 0h shift.\n",
    "    Restrict matching within the same 'Burrow'. Keep rows with time-of-day <07:00 or >20:00\n",
    "    and N > 0. Attach closest RFID's PIT_ID ('RFID'), 'Rdr', and unified 'RFID_Time'.\n",
    "    Accumulates results across ALL burrows.\n",
    "    \"\"\"\n",
    "    tol = pd.to_timedelta(window)\n",
    "\n",
    "    # Pick RFID datetime column if not provided\n",
    "    if rfid_time_col is None:\n",
    "        if \"PIT_DateTime\" in df_RFID.columns:\n",
    "            rfid_time_col = \"PIT_DateTime\"\n",
    "        elif \"DateTime\" in df_RFID.columns:\n",
    "            rfid_time_col = \"DateTime\"\n",
    "        else:\n",
    "            raise KeyError(\"No RFID datetime column found (need 'PIT_DateTime' or 'DateTime').\")\n",
    "\n",
    "    mom = df_MOM.copy()\n",
    "    rfid = df_RFID.copy()\n",
    "\n",
    "    # Require Burrow on both sides\n",
    "    if \"Burrow\" not in mom.columns or \"Burrow\" not in rfid.columns:\n",
    "        raise KeyError(\"Both df_MOM and df_RFID must contain a 'Burrow' column.\")\n",
    "\n",
    "    # Normalize\n",
    "    mom[\"Burrow\"] = mom[\"Burrow\"].astype(str)\n",
    "    rfid[\"Burrow\"] = rfid[\"Burrow\"].astype(str)\n",
    "\n",
    "    # Parse datetimes\n",
    "    mom[mom_time_col] = pd.to_datetime(mom[mom_time_col], errors=\"coerce\")\n",
    "    rfid[rfid_time_col] = pd.to_datetime(rfid[rfid_time_col], errors=\"coerce\")\n",
    "\n",
    "    # Build both time bases for RFID\n",
    "    rfid[\"_join_time_shift\"] = rfid[rfid_time_col] - pd.Timedelta(hours=1)  # -1h\n",
    "    rfid[\"_join_time_zero\"]  = rfid[rfid_time_col]                          # 0h\n",
    "\n",
    "    # Precompute per-burrow arrays for counts (shifted and zero)\n",
    "    rfid_valid_shift = rfid.dropna(subset=[\"_join_time_shift\"])\n",
    "    rfid_valid_zero  = rfid.dropna(subset=[\"_join_time_zero\"])\n",
    "\n",
    "    rfid_groups_shift = {\n",
    "        b: grp[\"_join_time_shift\"].sort_values().to_numpy(dtype=\"datetime64[ns]\")\n",
    "        for b, grp in rfid_valid_shift.groupby(\"Burrow\", sort=False)\n",
    "    }\n",
    "    rfid_groups_zero = {\n",
    "        b: grp[\"_join_time_zero\"].sort_values().to_numpy(dtype=\"datetime64[ns]\")\n",
    "        for b, grp in rfid_valid_zero.groupby(\"Burrow\", sort=False)\n",
    "    }\n",
    "\n",
    "    # Count matches for each MOM row: try shifted first; if 0, try zero\n",
    "    N = np.zeros(len(mom), dtype=int)\n",
    "    tol_ns = np.int64(tol.value)\n",
    "    mom_times = mom[mom_time_col].to_numpy(dtype=\"datetime64[ns]\")\n",
    "    mom_bur   = mom[\"Burrow\"].to_numpy()\n",
    "    used_offset = np.full(len(mom), fill_value=-3600, dtype=int)  # -3600 if shifted used, 0 if zero used\n",
    "\n",
    "    def count_in(arr, t_ns):\n",
    "        if arr.size == 0:\n",
    "            return 0\n",
    "        low  = (t_ns - tol_ns).view(\"datetime64[ns]\")\n",
    "        high = (t_ns + tol_ns).view(\"datetime64[ns]\")\n",
    "        left  = np.searchsorted(arr, low, side=\"left\")\n",
    "        right = np.searchsorted(arr, high, side=\"right\")\n",
    "        return right - left\n",
    "\n",
    "    for i, (t, b) in enumerate(zip(mom_times, mom_bur)):\n",
    "        if np.isnat(t):\n",
    "            continue\n",
    "        t_ns = t.astype(\"int64\")\n",
    "\n",
    "        # 1) shifted\n",
    "        if b in rfid_groups_shift:\n",
    "            c = count_in(rfid_groups_shift[b], t_ns)\n",
    "            if c > 0:\n",
    "                N[i] = c\n",
    "                continue  # keep -3600 marker\n",
    "\n",
    "        # 2) zero as fallback\n",
    "        if b in rfid_groups_zero:\n",
    "            c0 = count_in(rfid_groups_zero[b], t_ns)\n",
    "            if c0 > 0:\n",
    "                N[i] = c0\n",
    "                used_offset[i] = 0  # mark fallback used\n",
    "\n",
    "    mom[\"n_Matches\"] = N\n",
    "\n",
    "    # Filter: <07:00 or >20:00 AND N > 0\n",
    "    valid_time = mom[mom_time_col].notna()\n",
    "    hours_mask = valid_time & ((mom[mom_time_col].dt.hour < 7) | (mom[mom_time_col].dt.hour > 20))\n",
    "    # matches_mask = mom[\"n_Matches\"] > 0\n",
    "    # reduced = mom.loc[hours_mask & matches_mask].copy()\n",
    "    # reduced[\"_offset_used\"] = used_offset[hours_mask & matches_mask]\n",
    "    reduced = mom.loc[valid_time & hours_mask].copy()   # no `N>0` requirement\n",
    "\n",
    "    if reduced.empty:\n",
    "        reduced[\"RFID\"] = pd.Series(dtype=object)\n",
    "        reduced[\"Rdr\"]  = pd.Series(dtype=object)\n",
    "        reduced[\"RFID_Time\"] = pd.Series(dtype=\"datetime64[ns]\")\n",
    "        return reduced\n",
    "\n",
    "    # --- Accumulate per-burrow merges with fallback ---\n",
    "    pieces = []\n",
    "    for b, mom_g in reduced.groupby(\"Burrow\", sort=False):\n",
    "        # Prepare per-burrow RFID subsets\n",
    "        rfid_g_shift = rfid_valid_shift[rfid_valid_shift[\"Burrow\"] == b].sort_values(\"_join_time_shift\", kind=\"mergesort\")\n",
    "        rfid_g_zero  = rfid_valid_zero [rfid_valid_zero [\"Burrow\"] == b].sort_values(\"_join_time_zero\",  kind=\"mergesort\")\n",
    "\n",
    "        # Split MOM rows by which offset they used (per-row decision)\n",
    "        mom_shift = mom_g[mom_g[\"_offset_used\"] == -3600].dropna(subset=[mom_time_col]).sort_values(mom_time_col, kind=\"mergesort\")\n",
    "        mom_zero  = mom_g[mom_g[\"_offset_used\"] == 0     ].dropna(subset=[mom_time_col]).sort_values(mom_time_col, kind=\"mergesort\")\n",
    "\n",
    "        merged_parts = []\n",
    "\n",
    "        if not mom_shift.empty and not rfid_g_shift.empty:\n",
    "            m_shift = pd.merge_asof(\n",
    "                mom_shift,\n",
    "                rfid_g_shift[[\"_join_time_shift\", \"PIT_ID\", \"Rdr\", \"RF_File\", \"Burrow\"]],\n",
    "                left_on=mom_time_col,\n",
    "                right_on=\"_join_time_shift\",\n",
    "                direction=\"nearest\",\n",
    "                tolerance=tol,\n",
    "            )\n",
    "            m_shift[\"RFID_Time\"] = m_shift[\"_join_time_shift\"]\n",
    "            merged_parts.append(m_shift)\n",
    "\n",
    "        if not mom_zero.empty and not rfid_g_zero.empty:\n",
    "            m_zero = pd.merge_asof(\n",
    "                mom_zero,\n",
    "                rfid_g_zero[[\"_join_time_zero\", \"PIT_ID\", \"Rdr\", \"RF_File\", \"Burrow\"]],\n",
    "                left_on=mom_time_col,\n",
    "                right_on=\"_join_time_zero\",\n",
    "                direction=\"nearest\",\n",
    "                tolerance=tol,\n",
    "            )\n",
    "            m_zero[\"RFID_Time\"] = m_zero[\"_join_time_zero\"]\n",
    "            merged_parts.append(m_zero)\n",
    "\n",
    "        if merged_parts:\n",
    "            merged_g = pd.concat(merged_parts, ignore_index=False).sort_index(kind=\"mergesort\")\n",
    "        else:\n",
    "            # No RFID rows at all for this burrow (should be rare because N>0)\n",
    "            merged_g = mom_g.copy()\n",
    "            merged_g[\"PIT_ID\"] = pd.NA\n",
    "            merged_g[\"Rdr\"] = pd.NA\n",
    "            merged_g[\"RF_File\"] = pd.NA\n",
    "            merged_g[\"RFID_Time\"] = pd.NaT\n",
    "\n",
    "        # Finalize group\n",
    "        merged_g[\"RFID\"] = merged_g[\"PIT_ID\"]\n",
    "        pieces.append(merged_g)\n",
    "\n",
    "    out = pd.concat(pieces, ignore_index=False).sort_index(kind=\"mergesort\")\n",
    "\n",
    "    # Optional legacy renames if present\n",
    "    rename_map = {}\n",
    "    if \"Trace_Segment_Num\" in out.columns:\n",
    "        rename_map[\"Trace_Segment_Num\"] = \"Segmnt\"\n",
    "    if \"Wt_Min_Slope\" in out.columns:\n",
    "        rename_map[\"Wt_Min_Slope\"] = \"Wt\"\n",
    "    if \"_join_time\" in out.columns:\n",
    "        rename_map[\"_join_time\"] = \"Closest_RFID_Time\"\n",
    "    if \"n_Matches\" in out.columns:\n",
    "        rename_map[\"n_Matches\"] = \"N\"\n",
    "    if \"DateTime\" in out.columns:\n",
    "        rename_map[\"DateTime\"] = \"MOM_Time\"\n",
    "    if \"Burrow_x\" in out.columns:\n",
    "        rename_map[\"Burrow_x\"] = \"Burrow\"\n",
    "    if rename_map:\n",
    "        out = out.rename(columns=rename_map)\n",
    "    \n",
    "    # sort by \n",
    "    # Sort using Burrow while it's still present\n",
    "    out = out.sort_values([\"Burrow\", \"MOM_Time\"], kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "    # Now drop the extra columns\n",
    "    out = out.drop(columns=[\"PIT_ID\", \"Burrow_y\"], errors=\"ignore\")\n",
    "\n",
    "    # Order output columns\n",
    "    desired_order = [\"Burrow\", \"MOM_File\", \"MOM_Time\", \"Segment\", \"Wt\", \"RFID\", \"N\", \"Rdr\", \"Closest_RFID_Time\", \"RF_File\"]\n",
    "    out = out[[col for col in desired_order if col in out.columns]]\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b485ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              MOM_File Segment             DateTime  Wt_Min_Slope Burrow\n",
      "0  DL_06_24_2025_3.TXT       1  2025-06-24 16:18:32         50.00    5_3\n",
      "1  DL_06_24_2025_3.TXT       2  2025-06-24 16:18:48         98.71    5_3\n",
      "2  DL_06_24_2025_3.TXT       3  2025-06-25 03:00:47         42.88    5_3\n",
      "3  DL_06_24_2025_3.TXT       4  2025-06-25 08:29:24         49.97    5_3\n",
      "4  DL_06_24_2025_3.TXT       5  2025-06-25 08:29:45         99.78    5_3\n"
     ]
    }
   ],
   "source": [
    "print(df_WtFiles.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "2050f778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['003', '059', '087', '097', '206', '219', '227', '230', '235', '252', '265', '270', '349', '352', '359', '362', '367', '369', '372', '376', '377', '379', '380', '382', '388', '933', '952', '975']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(df_WtFiles['Burrow'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "40b507fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Burrow                 MOM_File            MOM_Time      Wt        RFID  \\\n",
      "0      3      DL_06_16_2025_3.TXT 2025-06-17 03:20:50   46.17         NaN   \n",
      "1      3      DL_06_17_2025_3.TXT 2025-06-17 22:31:14   54.19         NaN   \n",
      "2      3      DL_06_24_2025_3.TXT 2025-06-25 03:00:47   42.88         NaN   \n",
      "0     59     DL_06_13_2025_59.TXT 2025-06-14 00:44:53   42.51  0620000AB9   \n",
      "1     59     DL_06_14_2025_59.TXT 2025-06-14 23:50:48   52.50  0620000B98   \n",
      "2     59     DL_06_17_2025_59.TXT 2025-06-18 02:57:25   45.57  0620000B98   \n",
      "3     59     DL_06_18_2025_59.TXT 2025-06-18 23:46:03   47.22  0620000AB9   \n",
      "4     59     DL_06_20_2025_59.TXT 2025-06-21 02:11:23   50.42         NaN   \n",
      "5     59     DL_06_20_2025_59.TXT 2025-06-21 02:24:22   44.95         NaN   \n",
      "6     59     DL_06_23_2025_59.TXT 2025-06-24 00:24:07   50.22  0620000AB9   \n",
      "7     59     DL_06_23_2025_59.TXT 2025-06-24 00:40:02   42.92  0620000B98   \n",
      "0     87     DL_06_25_2025_87.TXT 2000-01-01 00:00:00   50.21         NaN   \n",
      "1     87     DL_06_25_2025_87.TXT 2000-01-01 00:00:00   99.99         NaN   \n",
      "2     87     DL_06_25_2025_87.TXT 2000-01-01 00:00:00   51.72         NaN   \n",
      "3     87     DL_06_25_2025_87.TXT 2000-01-01 00:00:00   38.63         NaN   \n",
      "4     87     DL_06_25_2025_87.TXT 2000-01-01 00:00:00   50.24         NaN   \n",
      "5     87     DL_06_25_2025_87.TXT 2000-01-01 00:00:00  100.09         NaN   \n",
      "6     87  DL_06_17-18_2025_87.TXT 2000-01-01 00:00:00   50.22         NaN   \n",
      "7     87  DL_06_17-18_2025_87.TXT 2000-01-01 00:00:00   99.96         NaN   \n",
      "8     87  DL_06_17-18_2025_87.TXT 2000-01-01 00:00:00   50.11         NaN   \n",
      "\n",
      "     N  Rdr           RFID_Time               RF_File  \n",
      "0    0  NaN                 NaT                   NaN  \n",
      "1    0  NaN                 NaT                   NaN  \n",
      "2    0  NaN                 NaT                   NaN  \n",
      "0  238  1.0 2025-06-14 00:44:15  RF_06_14_2025_59.TXT  \n",
      "1   42  2.0 2025-06-14 23:49:56  RF_06_14_2025_59.TXT  \n",
      "2  184  1.0 2025-06-18 02:56:20  RF_06_18_2025_59.TXT  \n",
      "3   15  1.0 2025-06-18 23:44:54  RF_06_18_2025_59.TXT  \n",
      "4    0  NaN                 NaT                   NaN  \n",
      "5    0  NaN                 NaT                   NaN  \n",
      "6   12  1.0 2025-06-24 00:22:31  RF_06_23_2025_59.TXT  \n",
      "7   27  1.0 2025-06-24 00:38:27  RF_06_23_2025_59.TXT  \n",
      "0    0  NaN                 NaT                   NaN  \n",
      "1    0  NaN                 NaT                   NaN  \n",
      "2    0  NaN                 NaT                   NaN  \n",
      "3    0  NaN                 NaT                   NaN  \n",
      "4    0  NaN                 NaT                   NaN  \n",
      "5    0  NaN                 NaT                   NaN  \n",
      "6    0  NaN                 NaT                   NaN  \n",
      "7    0  NaN                 NaT                   NaN  \n",
      "8    0  NaN                 NaT                   NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xp/8z1j89ns7md79c4g_c7r5g6m0000gn/T/ipykernel_1393/4003654353.py:169: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  out = pd.concat(pieces, ignore_index=False).sort_index(kind=\"mergesort\")\n"
     ]
    }
   ],
   "source": [
    "df_MOM_with_counts = join_MOM_RFID2(df_WtFiles, df_rfid, window=\"3min\")\n",
    "print(df_MOM_with_counts.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "f419e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def join_MOM_RFID2(\n",
    "    df_MOM: pd.DataFrame,\n",
    "    df_RFID: pd.DataFrame,\n",
    "    window: str = \"2min\",\n",
    "    mom_time_col: str = \"DateTime\",\n",
    "    rfid_time_col: str | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Join MOM to nearest RFID within ±window, per Burrow.\n",
    "    - Try RFID shifted -1h; if N==0 for a MOM row, retry at 0h (no shift).\n",
    "    - Keep rows in hours <07:00 or >20:00 even if N==0.\n",
    "    - Return columns sorted by Burrow, MOM_Time; include RFID, Rdr, RFID_Time.\n",
    "    \"\"\"\n",
    "\n",
    "    tol = pd.to_timedelta(window)\n",
    "\n",
    "    # Pick RFID datetime column if not provided\n",
    "    if rfid_time_col is None:\n",
    "        if \"PIT_DateTime\" in df_RFID.columns:\n",
    "            rfid_time_col = \"PIT_DateTime\"\n",
    "        elif \"DateTime\" in df_RFID.columns:\n",
    "            rfid_time_col = \"DateTime\"\n",
    "        else:\n",
    "            raise KeyError(\"No RFID datetime column found (need 'PIT_DateTime' or 'DateTime').\")\n",
    "\n",
    "    mom = df_MOM.copy()\n",
    "    rfid = df_RFID.copy()\n",
    "\n",
    "    # Ensure Burrow exists\n",
    "    if \"Burrow\" not in mom.columns or \"Burrow\" not in rfid.columns:\n",
    "        raise KeyError(\"Both df_MOM and df_RFID must contain a 'Burrow' column.\")\n",
    "\n",
    "    # Canonicalize burrow (digits only, last 3, zero-padded)\n",
    "    def canon_burrow(s: pd.Series) -> pd.Series:\n",
    "        return (\n",
    "            s.astype(str)\n",
    "             .str.replace(r\"\\D\", \"\", regex=True)\n",
    "             .str[-3:]\n",
    "             .str.zfill(3)\n",
    "        )\n",
    "\n",
    "    mom[\"_BurrowKey\"]  = canon_burrow(mom[\"Burrow\"])\n",
    "    rfid[\"_BurrowKey\"] = canon_burrow(rfid[\"Burrow\"])\n",
    "\n",
    "    # Parse datetimes\n",
    "    mom[mom_time_col]   = pd.to_datetime(mom[mom_time_col], errors=\"coerce\")\n",
    "    rfid[rfid_time_col] = pd.to_datetime(rfid[rfid_time_col], errors=\"coerce\")\n",
    "\n",
    "    # Build join times (shifted and zero)\n",
    "    rfid[\"_join_time_shift\"] = rfid[rfid_time_col] - pd.Timedelta(hours=1)\n",
    "    rfid[\"_join_time_zero\"]  = rfid[rfid_time_col]\n",
    "\n",
    "    # Valid RFID per mode\n",
    "    rfid_shift = rfid.dropna(subset=[\"_join_time_shift\"])\n",
    "    rfid_zero  = rfid.dropna(subset=[\"_join_time_zero\"])\n",
    "\n",
    "    # Count matches per MOM row (try shift, then zero)\n",
    "    N = np.zeros(len(mom), dtype=int)\n",
    "    used_offset = np.full(len(mom), -3600, dtype=int)  # -3600 (shift) by default; 0 for zero-shift\n",
    "\n",
    "    tol_ns = np.int64(tol.value)\n",
    "    mom_times_ns = mom[mom_time_col].to_numpy(dtype=\"datetime64[ns]\")\n",
    "    mom_bkeys    = mom[\"_BurrowKey\"].to_numpy()\n",
    "\n",
    "    # Precompute per-burrow arrays\n",
    "    def arr_map(df: pd.DataFrame, col: str) -> dict:\n",
    "        return {\n",
    "            k: g[col].sort_values().to_numpy(dtype=\"datetime64[ns]\")\n",
    "            for k, g in df.groupby(\"_BurrowKey\", sort=False)\n",
    "        }\n",
    "\n",
    "    arr_shift = arr_map(rfid_shift, \"_join_time_shift\")\n",
    "    arr_zero  = arr_map(rfid_zero,  \"_join_time_zero\")\n",
    "\n",
    "    def count_in(arr: np.ndarray, t_int: np.int64) -> int:\n",
    "        if arr.size == 0:\n",
    "            return 0\n",
    "        low  = (t_int - tol_ns).view(\"datetime64[ns]\")\n",
    "        high = (t_int + tol_ns).view(\"datetime64[ns]\")\n",
    "        L = np.searchsorted(arr, low,  side=\"left\")\n",
    "        R = np.searchsorted(arr, high, side=\"right\")\n",
    "        return R - L\n",
    "\n",
    "    for i, (t, bk) in enumerate(zip(mom_times_ns, mom_bkeys)):\n",
    "        if np.isnat(t) or not isinstance(bk, (str, np.str_)):\n",
    "            continue\n",
    "        t_int = t.astype(\"int64\")\n",
    "\n",
    "        # Try shifted\n",
    "        arr = arr_shift.get(bk)\n",
    "        c = count_in(arr, t_int) if arr is not None else 0\n",
    "        if c > 0:\n",
    "            N[i] = c\n",
    "            continue\n",
    "\n",
    "        # Fallback: zero\n",
    "        arr0 = arr_zero.get(bk)\n",
    "        c0 = count_in(arr0, t_int) if arr0 is not None else 0\n",
    "        if c0 > 0:\n",
    "            N[i] = c0\n",
    "            used_offset[i] = 0\n",
    "\n",
    "    mom[\"n_Matches\"] = N\n",
    "\n",
    "    # Keep rows in target hours (even if N==0)\n",
    "    valid_time = mom[mom_time_col].notna()\n",
    "    hours_mask = valid_time & ((mom[mom_time_col].dt.hour < 7) | (mom[mom_time_col].dt.hour > 20))\n",
    "    reduced = mom.loc[hours_mask].copy()\n",
    "\n",
    "    # Attach per-row offset_used (aligned by index for safety)\n",
    "    reduced[\"_offset_used\"] = pd.Series(used_offset, index=mom.index).loc[reduced.index].values\n",
    "\n",
    "    # --- Merge nearest per mode, per burrow key ---\n",
    "    pieces = []\n",
    "    for bk, mom_g in reduced.groupby(\"_BurrowKey\", sort=False):\n",
    "\n",
    "        # Split MOM rows by which offset they used (or default -3600)\n",
    "        mom_shift = mom_g[mom_g[\"_offset_used\"] == -3600].dropna(subset=[mom_time_col])\n",
    "        mom_zero  = mom_g[mom_g[\"_offset_used\"] == 0     ].dropna(subset=[mom_time_col])\n",
    "\n",
    "        # Right sides for this burrow key\n",
    "        r_shift_b = rfid_shift[rfid_shift[\"_BurrowKey\"] == bk].sort_values(\"_join_time_shift\", kind=\"mergesort\")\n",
    "        r_zero_b  = rfid_zero [rfid_zero [\"_BurrowKey\"] == bk].sort_values(\"_join_time_zero\",  kind=\"mergesort\")\n",
    "\n",
    "        merged_parts = []\n",
    "\n",
    "        if not mom_shift.empty and not r_shift_b.empty:\n",
    "            m1 = pd.merge_asof(\n",
    "                mom_shift.sort_values(mom_time_col, kind=\"mergesort\"),\n",
    "                r_shift_b[[\"_join_time_shift\", \"PIT_ID\", \"Rdr\", \"RF_File\", \"_BurrowKey\"]],\n",
    "                left_on=mom_time_col,\n",
    "                right_on=\"_join_time_shift\",\n",
    "                by=\"_BurrowKey\",\n",
    "                direction=\"nearest\",\n",
    "                tolerance=tol,\n",
    "            )\n",
    "            m1[\"RFID_Time\"] = m1[\"_join_time_shift\"]\n",
    "            merged_parts.append(m1)\n",
    "\n",
    "        if not mom_zero.empty and not r_zero_b.empty:\n",
    "            m2 = pd.merge_asof(\n",
    "                mom_zero.sort_values(mom_time_col, kind=\"mergesort\"),\n",
    "                r_zero_b[[\"_join_time_zero\", \"PIT_ID\", \"Rdr\", \"RF_File\", \"_BurrowKey\"]],\n",
    "                left_on=mom_time_col,\n",
    "                right_on=\"_join_time_zero\",\n",
    "                by=\"_BurrowKey\",\n",
    "                direction=\"nearest\",\n",
    "                tolerance=tol,\n",
    "            )\n",
    "            m2[\"RFID_Time\"] = m2[\"_join_time_zero\"]\n",
    "            merged_parts.append(m2)\n",
    "\n",
    "        if merged_parts:\n",
    "            merged_g = pd.concat(merged_parts, ignore_index=False).sort_index(kind=\"mergesort\")\n",
    "        else:\n",
    "            # No RFID rows for this burrow (or none within tolerance): keep MOM rows with NaNs\n",
    "            merged_g = mom_g.copy()\n",
    "            merged_g[\"PIT_ID\"] = pd.NA\n",
    "            merged_g[\"Rdr\"] = pd.NA\n",
    "            merged_g[\"RF_File\"] = pd.NA\n",
    "            merged_g[\"RFID_Time\"] = pd.NaT\n",
    "\n",
    "        merged_g[\"RFID\"] = merged_g[\"PIT_ID\"]\n",
    "        pieces.append(merged_g)\n",
    "\n",
    "    out = pd.concat(pieces, ignore_index=False).sort_index(kind=\"mergesort\")\n",
    "\n",
    "    # Rename to your schema\n",
    "    rename_map = {}\n",
    "    if \"Trace_Segment_Num\" in out.columns:\n",
    "        rename_map[\"Trace_Segment_Num\"] = \"Segmnt\"\n",
    "    if \"Wt_Min_Slope\" in out.columns:\n",
    "        rename_map[\"Wt_Min_Slope\"] = \"Wt\"\n",
    "    if \"n_Matches\" in out.columns:\n",
    "        rename_map[\"n_Matches\"] = \"N\"\n",
    "    if \"DateTime\" in out.columns:\n",
    "        rename_map[\"DateTime\"] = \"MOM_Time\"\n",
    "    out = out.rename(columns=rename_map)\n",
    "\n",
    "    # Clean up helpers\n",
    "    out = out.drop(columns=[\"_join_time_shift\", \"_join_time_zero\", \"PIT_ID\"], errors=\"ignore\")\n",
    "\n",
    "    # Sort & order columns\n",
    "    # out = out.sort_values([\"Burrow\", \"MOM_Time\"], kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "    desired_order = [\"Burrow\", \"MOM_File\", \"MOM_Time\", \"Segmnt\", \"Wt\", \"RFID\", \"N\", \"Rdr\", \"RFID_Time\", \"RF_File\"]\n",
    "    out = out[[c for c in desired_order if c in out.columns]]\n",
    "\n",
    "    out[\"Burrow\"] = out[\"Burrow\"].astype(str).apply(clean_burrow)\n",
    "\n",
    "        # Sort by numeric Burrow when possible, then MOM_Time\n",
    "    out[\"Burrow_sort\"] = pd.to_numeric(out[\"Burrow\"], errors=\"coerce\")\n",
    "\n",
    "    out = out.sort_values([\"Burrow_sort\", \"MOM_Time\"], kind=\"mergesort\").drop(columns=[\"Burrow_sort\"])\n",
    "\n",
    "    # print(\"out df:\")\n",
    "    # print(out.head(2))\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "c1e72673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out df:\n",
      "  Burrow             MOM_File            MOM_Time     Wt RFID  N  Rdr  \\\n",
      "0    003  DL_06_16_2025_3.TXT 2025-06-17 03:20:50  46.17  NaN  0  NaN   \n",
      "1    003  DL_06_17_2025_3.TXT 2025-06-17 22:31:14  54.19  NaN  0  NaN   \n",
      "\n",
      "  RFID_Time RF_File  \n",
      "0       NaT     NaN  \n",
      "1       NaT     NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xp/8z1j89ns7md79c4g_c7r5g6m0000gn/T/ipykernel_1393/3673339606.py:169: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  out = pd.concat(pieces, ignore_index=False).sort_index(kind=\"mergesort\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Burrow</th>\n",
       "      <th>MOM_File</th>\n",
       "      <th>MOM_Time</th>\n",
       "      <th>Wt</th>\n",
       "      <th>RFID</th>\n",
       "      <th>N</th>\n",
       "      <th>Rdr</th>\n",
       "      <th>RFID_Time</th>\n",
       "      <th>RF_File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>952</td>\n",
       "      <td>DL_06_25_2025_952.TXT</td>\n",
       "      <td>2025-06-25 22:57:02</td>\n",
       "      <td>46.77</td>\n",
       "      <td>0620000B64</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2025-06-25 22:55:09</td>\n",
       "      <td>RF_06_25_2025_952.TXT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>952</td>\n",
       "      <td>DL_06_25_2025_952.TXT</td>\n",
       "      <td>2025-06-25 23:03:18</td>\n",
       "      <td>40.52</td>\n",
       "      <td>0620000C6F</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2025-06-25 23:01:21</td>\n",
       "      <td>RF_06_25_2025_952.TXT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>970</td>\n",
       "      <td>DL_07_09-10_2025_970.TXT</td>\n",
       "      <td>2025-07-09 23:12:08</td>\n",
       "      <td>40.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>970</td>\n",
       "      <td>DL_07_09-10_2025_970.TXT</td>\n",
       "      <td>2025-07-09 23:29:15</td>\n",
       "      <td>55.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>970</td>\n",
       "      <td>DL_07_15_2025_970.TXT</td>\n",
       "      <td>2025-07-15 22:59:13</td>\n",
       "      <td>49.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>970</td>\n",
       "      <td>DL_07_15_2025_970.TXT</td>\n",
       "      <td>2025-07-15 23:09:49</td>\n",
       "      <td>38.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975</td>\n",
       "      <td>DL_06_13_2025_975.TXT</td>\n",
       "      <td>2025-06-13 22:31:09</td>\n",
       "      <td>54.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>975</td>\n",
       "      <td>DL_06_13_2025_975.TXT</td>\n",
       "      <td>2025-06-13 22:49:03</td>\n",
       "      <td>41.67</td>\n",
       "      <td>0620000B57</td>\n",
       "      <td>486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-06-13 22:48:24</td>\n",
       "      <td>RF_06_14_2025_975.TXT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>975</td>\n",
       "      <td>DL_06_20_2025_975.TXT</td>\n",
       "      <td>2025-06-21 01:41:13</td>\n",
       "      <td>42.84</td>\n",
       "      <td>0620000D10</td>\n",
       "      <td>138</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2025-06-21 01:39:22</td>\n",
       "      <td>RF_06_21-22_2025_975.TXT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>975</td>\n",
       "      <td>DL_06_26_2025_975.TXT</td>\n",
       "      <td>2025-06-27 00:05:02</td>\n",
       "      <td>50.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Burrow                  MOM_File            MOM_Time     Wt        RFID  \\\n",
       "6    952     DL_06_25_2025_952.TXT 2025-06-25 22:57:02  46.77  0620000B64   \n",
       "7    952     DL_06_25_2025_952.TXT 2025-06-25 23:03:18  40.52  0620000C6F   \n",
       "0    970  DL_07_09-10_2025_970.TXT 2025-07-09 23:12:08  40.98         NaN   \n",
       "1    970  DL_07_09-10_2025_970.TXT 2025-07-09 23:29:15  55.47         NaN   \n",
       "2    970     DL_07_15_2025_970.TXT 2025-07-15 22:59:13  49.21         NaN   \n",
       "3    970     DL_07_15_2025_970.TXT 2025-07-15 23:09:49  38.43         NaN   \n",
       "0    975     DL_06_13_2025_975.TXT 2025-06-13 22:31:09  54.06         NaN   \n",
       "1    975     DL_06_13_2025_975.TXT 2025-06-13 22:49:03  41.67  0620000B57   \n",
       "2    975     DL_06_20_2025_975.TXT 2025-06-21 01:41:13  42.84  0620000D10   \n",
       "3    975     DL_06_26_2025_975.TXT 2025-06-27 00:05:02  50.31         NaN   \n",
       "\n",
       "     N  Rdr           RFID_Time                   RF_File  \n",
       "6    8  2.0 2025-06-25 22:55:09     RF_06_25_2025_952.TXT  \n",
       "7   36  2.0 2025-06-25 23:01:21     RF_06_25_2025_952.TXT  \n",
       "0    0  NaN                 NaT                       NaN  \n",
       "1    0  NaN                 NaT                       NaN  \n",
       "2    0  NaN                 NaT                       NaN  \n",
       "3    0  NaN                 NaT                       NaN  \n",
       "0    0  NaN                 NaT                       NaN  \n",
       "1  486  1.0 2025-06-13 22:48:24     RF_06_14_2025_975.TXT  \n",
       "2  138  2.0 2025-06-21 01:39:22  RF_06_21-22_2025_975.TXT  \n",
       "3    0  NaN                 NaT                       NaN  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put it all together\n",
    "df_rfid = get_All_RFID_data(\"/Users/bobmauck/devel/Combo_App/Example_Data\")\n",
    "df_WtFiles = get_All_Mom_data(\"/Users/bobmauck/devel/Combo_App/Example_Data\")\n",
    "df_MOM_with_counts = join_MOM_RFID2(df_WtFiles, df_rfid, window=\"3min\")\n",
    "df_MOM_with_counts.tail(10)\n",
    "# df_MOM_with_counts.to_csv(\"df_MOM_with_counts.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4d9d9ddd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_MOM_with_counts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf_MOM_with_counts\u001b[49m.head(\u001b[32m10\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'df_MOM_with_counts' is not defined"
     ]
    }
   ],
   "source": [
    "print(df_MOM_with_counts.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c87c4e",
   "metadata": {},
   "source": [
    "New analyses to resolve issues when MOM RTC does not work and RFID RTC does work\n",
    "-- logic:\n",
    "    get rid of known calibration weights: consecutive 50 ± 0.5g  100 ± 5g \n",
    "    with what is left over - ID the Date from Filename\n",
    "    How many traces? 0, 1, 2, 3, 4?\n",
    "    look for RFID on that date's night > 8PM, > 7AM\n",
    "        unique ids in that time\n",
    "        determine order of arrival of the UID if >1 - i.e. get first time for each\n",
    "        if #UID = #Traces\n",
    "            if UniqueIDs =1 and 1 trace -- assign\n",
    "            if UIDs = 2 and 2 traces -- assign by order of trace occurance\n",
    "            i.e. assign by order\n",
    "        else -- put in note\n",
    "            if UIDs = 1 and > 1 Trace - put in note\n",
    "            if UIDs = 2 and 1 Trace -- put in note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bf83d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_outside_hours(df, datetime_col, hr_am, hr_pm):\n",
    "\n",
    "    # Ensure datetime\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[datetime_col]):\n",
    "        df = df.copy()\n",
    "        df[datetime_col] = pd.to_datetime(df[datetime_col], errors=\"coerce\")\n",
    "\n",
    "    valid_time = df[datetime_col].notna()\n",
    "    hours_mask = valid_time & (\n",
    "        (df[datetime_col].dt.hour < hr_am) |\n",
    "        (df[datetime_col].dt.hour > hr_pm)\n",
    "    )\n",
    "    return df.loc[hours_mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "679740a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def remove_spurious_pairs(\n",
    "    df: pd.DataFrame,\n",
    "    col: str = \"Wt_Min_Slope\",\n",
    "    low_val: float = 50.0,\n",
    "    high_val: float = 75.0,\n",
    "    tol: float = 0.6\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Removes spurious weight pairs:\n",
    "      - A value near `low_val` (±tol) immediately followed by a value > `high_val`.\n",
    "      - Any remaining values > `high_val`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe.\n",
    "    col : str\n",
    "        Column to test (default = \"Wt_Min_Slope\").\n",
    "    low_val : float\n",
    "        Target value for the first element in the pair (default = 50.0).\n",
    "    high_val : float\n",
    "        Threshold for the second element in the pair and final cleanup (default = 100.0).\n",
    "    tol : float\n",
    "        Allowed tolerance around low_val (default = 0.6).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Copy of dataframe with rows removed.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Step 1: detect low_val followed by high_val+\n",
    "    near_low = df[col].between(low_val - tol, low_val + tol)\n",
    "    over_high = df[col] > high_val\n",
    "\n",
    "    # pattern[i] = True if row i ≈ low_val and row i+1 > high_val\n",
    "    pattern = near_low & over_high.shift(-1)\n",
    "\n",
    "    # rows to drop: both the ≈low_val row and its following >high_val row\n",
    "    drop_idx = df.index[pattern | pattern.shift(1, fill_value=False)]\n",
    "\n",
    "    # Step 2: also remove any other stray > high_val rows\n",
    "    drop_idx = drop_idx.union(df.index[df[col] > high_val])\n",
    "\n",
    "    return df.drop(drop_idx).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcc24e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def earliest_per_pit(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a subset of df containing the earliest PIT_DateTime\n",
    "    record for each unique PIT_ID.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain ['PIT_ID', 'PIT_DateTime'].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Subset with earliest record for each PIT_ID.\n",
    "    \"\"\"\n",
    "    # make sure PIT_DateTime is datetime\n",
    "    df = df.copy()\n",
    "    df['PIT_DateTime'] = pd.to_datetime(df['PIT_DateTime'], errors='coerce')\n",
    "\n",
    "    # sort by PIT_ID then datetime\n",
    "    df = df.sort_values(['PIT_ID', 'PIT_DateTime'])\n",
    "\n",
    "    # keep first row for each PIT_ID\n",
    "    earliest = df.groupby('PIT_ID', as_index=False).first()\n",
    "\n",
    "    return earliest.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "62b3960b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF_MOM then DF_RIFD\n",
      "               MOM_File Segment             DateTime  Wt_Min_Slope Burrow\n",
      "0  DL_06_25_2025_87.TXT       3  2000-01-01 00:00:00         51.72    _87\n",
      "1  DL_06_25_2025_87.TXT       4  2000-01-01 00:00:00         38.63    _87\n",
      "           PIT_ID  Rdr        PIT_DateTime               RF_File Burrow\n",
      "47261  0620000C7A    1 2025-06-26 01:00:48  RF_06_25_2025_87.TXT    _87\n",
      "47262  0620000C7A    1 2025-06-26 01:00:49  RF_06_25_2025_87.TXT    _87\n",
      "47263  0620000C7A    2 2025-06-26 01:00:50  RF_06_25_2025_87.TXT    _87\n",
      "47264  0620000C7A    2 2025-06-26 01:00:51  RF_06_25_2025_87.TXT    _87\n",
      "47265  0620000DB6    2 2025-06-26 01:09:48  RF_06_25_2025_87.TXT    _87\n",
      "47266  0620000DB6    2 2025-06-26 01:10:05  RF_06_25_2025_87.TXT    _87\n",
      "47267  0620000DB6    2 2025-06-26 01:10:06  RF_06_25_2025_87.TXT    _87\n",
      "47268  0620000DB6    2 2025-06-26 01:10:07  RF_06_25_2025_87.TXT    _87\n",
      "47269  0620000DB6    2 2025-06-26 01:10:08  RF_06_25_2025_87.TXT    _87\n",
      "47270  0620000DB6    2 2025-06-26 01:10:09  RF_06_25_2025_87.TXT    _87\n",
      "47271  0620000DB6    2 2025-06-26 01:10:10  RF_06_25_2025_87.TXT    _87\n",
      "47272  0620000DB6    2 2025-06-26 01:10:11  RF_06_25_2025_87.TXT    _87\n",
      "47273  0620000DB6    2 2025-06-26 01:10:12  RF_06_25_2025_87.TXT    _87\n",
      "47274  0620000DB6    2 2025-06-26 01:10:13  RF_06_25_2025_87.TXT    _87\n",
      "47275  0620000DB6    2 2025-06-26 01:10:14  RF_06_25_2025_87.TXT    _87\n",
      "47276  0620000DB6    2 2025-06-26 01:10:15  RF_06_25_2025_87.TXT    _87\n",
      "47277  0620000DB6    2 2025-06-26 01:10:16  RF_06_25_2025_87.TXT    _87\n",
      "47278  0620000DB6    2 2025-06-26 01:10:17  RF_06_25_2025_87.TXT    _87\n",
      "47279  0620000DB6    2 2025-06-26 01:10:18  RF_06_25_2025_87.TXT    _87\n",
      "47280  0620000DB6    2 2025-06-26 01:10:19  RF_06_25_2025_87.TXT    _87\n",
      "UIDs and time encounterd:\n",
      "       PIT_ID  Rdr        PIT_DateTime               RF_File Burrow\n",
      "0  0620000C7A    1 2025-06-26 01:00:48  RF_06_25_2025_87.TXT    _87\n",
      "1  0620000DB6    2 2025-06-26 01:09:48  RF_06_25_2025_87.TXT    _87\n",
      "  Burrow              MOM_File             MOM_Time Segment        RFID  N  \\\n",
      "0    _87  DL_06_25_2025_87.TXT  2000-01-01 00:00:00       3  0620000C7A  1   \n",
      "1    _87  DL_06_25_2025_87.TXT  2000-01-01 00:00:00       4  0620000DB6  1   \n",
      "\n",
      "   Rdr           RFID_Time               RF_File  \n",
      "0    1 2025-06-26 01:00:48  RF_06_25_2025_87.TXT  \n",
      "1    2 2025-06-26 01:09:48  RF_06_25_2025_87.TXT  \n"
     ]
    }
   ],
   "source": [
    "# get what we need\n",
    "import pandas as pd\n",
    "\n",
    "# get all the data in the folder\n",
    "df_rfid = get_All_RFID_data(\"/Users/bobmauck/devel/Combo_App/Example_Data\")\n",
    "df_WtFiles = get_All_Mom_data(\"/Users/bobmauck/devel/Combo_App/Example_Data\")\n",
    "\n",
    "# let's work with one file at a time - note that the file has to end in _87, not 087. check if you get nothing found\n",
    "my_Burr = '_87'\n",
    "# just get the subset of both df that we want to test \n",
    "df_subset_mom = df_WtFiles[df_WtFiles['Burrow'] == my_Burr].copy()\n",
    "df_subset_rfid = df_rfid[df_rfid['Burrow'] == my_Burr].copy()\n",
    "\n",
    "# just get the subset of day that we want to test - start with the string which is all we have with MOM data \n",
    "my_Day_str = \"06_25_2025\"\n",
    "df_subset_mom_day = df_subset_mom[df_subset_mom[\"MOM_File\"].str.contains(my_Day_str, na=False)].copy()\n",
    "\n",
    "# next find RFID with the actual date and time by turning the string into an actual date, then applying that to PIT_DateTime\n",
    "df_subset_rfid['PIT_DateTime'] = pd.to_datetime(df_subset_rfid['PIT_DateTime'], errors=\"coerce\")\n",
    "\n",
    "# next, covert make my_Day_str into a real date time - my_Day\n",
    "my_Day = pd.to_datetime(my_Day_str, format=\"%m_%d_%Y\")\n",
    "\n",
    "start = my_Day + pd.Timedelta(hours=20)        # 2025-06-05 20:00\n",
    "end   = my_Day + pd.Timedelta(days=1, hours=7) # 2025-06-06 07:00\n",
    "\n",
    "if False:\n",
    "    print(\"Start:\", start)\n",
    "    print(\"End:\", end)\n",
    "    print(\"Min PIT_DateTime:\", df_subset_rfid['PIT_DateTime'].min())\n",
    "    print(\"Max PIT_DateTime:\", df_subset_rfid['PIT_DateTime'].max())\n",
    "\n",
    "# find only those RFID records in that timespan\n",
    "df_subset_rfid_day = df_subset_rfid[\n",
    "    (df_subset_rfid['PIT_DateTime'] > start) & \n",
    "    (df_subset_rfid['PIT_DateTime'] < end)\n",
    "].copy()\n",
    "\n",
    "\n",
    "df_Final_mom = remove_spurious_pairs(df_subset_mom_day, col=\"Wt_Min_Slope\", low_val=50, high_val=80, tol=1.0)\n",
    "print(\"DF_MOM then DF_RIFD\")\n",
    "print(df_Final_mom)\n",
    "print(df_subset_rfid_day.head(20))\n",
    "\n",
    "print(\"UIDs and time encounterd:\")\n",
    "subset_df = earliest_per_pit(df_subset_rfid_day)\n",
    "print(subset_df.head(2))\n",
    "\n",
    "#### from below, putting it all together\n",
    "df_joined_inc = join_MOM_RFID_phase(df_Final_mom, subset_df, repro_phase=\"inc\")\n",
    "print(df_joined_inc.head())\n",
    "\n",
    "\n",
    "if False:\n",
    "    df_MOM_with_counts = join_MOM_RFID2(df_WtFiles, df_rfid, window=\"3min\")\n",
    "    df_MOM_with_counts.to_csv(\"df_MOM_with_counts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "68e17d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def join_MOM_RFID_phase(df_MOM: pd.DataFrame, df_RF: pd.DataFrame, repro_phase: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Join MOM and RFID data depending on the reproductive phase.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_MOM : pd.DataFrame\n",
    "        MOM dataframe (already processed, has columns like MOM_File, Segment, DateTime, Wt, Burrow, etc.)\n",
    "    df_RF : pd.DataFrame\n",
    "        RFID dataframe (already processed, has columns like PIT_ID, Rdr, PIT_DateTime, RF_File, Burrow, etc.)\n",
    "    repro_phase : str\n",
    "        The reproductive phase (\"inc\" or other values for future use)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Joined dataframe similar to join_MOM_RFID2 output\n",
    "    \"\"\"\n",
    "    if repro_phase == \"inc\":\n",
    "        if len(df_MOM) != len(df_RF):\n",
    "            raise ValueError(\n",
    "                f\"For repro_phase='inc', df_MOM ({len(df_MOM)}) and df_RF ({len(df_RF)}) must have the same number of rows.\"\n",
    "            )\n",
    "\n",
    "        # Join in order\n",
    "        df_joined = pd.concat([df_MOM.reset_index(drop=True), df_RF.reset_index(drop=True)], axis=1)\n",
    "\n",
    "        # Rename to match join_MOM_RFID2 style\n",
    "        rename_map = {\n",
    "            \"Trace_Segment_Num\": \"Segment\",\n",
    "            \"Wt_Min_Slope\": \"Wt\",\n",
    "            \"DateTime\": \"MOM_Time\",\n",
    "            \"PIT_DateTime\": \"RFID_Time\",\n",
    "            \"PIT_ID\": \"RFID\",\n",
    "        }\n",
    "        df_joined = df_joined.rename(columns=rename_map)\n",
    "\n",
    "        # Add n_Matches (since each MOM row matches exactly one RFID row here)\n",
    "        df_joined[\"N\"] = 1\n",
    "\n",
    "        # Reorder columns to look like join_MOM_RFID2 output\n",
    "        desired_order = [\n",
    "            \"Burrow\", \"MOM_File\", \"MOM_Time\", \"Segment\", \"Wt_Min_Slope\",\n",
    "            \"RFID\", \"N\", \"Rdr\", \"RFID_Time\", \"RF_File\"\n",
    "        ]\n",
    "        df_joined = df_joined[[col for col in desired_order if col in df_joined.columns]]\n",
    "\n",
    "        # drop the duplicate Burrow (keep the one from df_MOM, which comes first)\n",
    "    if \"Burrow\" in df_joined.columns:\n",
    "        df_joined = df_joined.loc[:, ~df_joined.columns.duplicated()]\n",
    "\n",
    "        return df_joined\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Repro phase '{repro_phase}' not yet implemented.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ec222194",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "For repro_phase='inc', df_MOM (2) and df_RF (0) must have the same number of rows.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_joined_inc = \u001b[43mjoin_MOM_RFID_phase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_Final_mom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubset_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepro_phase\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_joined_inc.head())\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mjoin_MOM_RFID_phase\u001b[39m\u001b[34m(df_MOM, df_RF, repro_phase)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m repro_phase == \u001b[33m\"\u001b[39m\u001b[33minc\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df_MOM) != \u001b[38;5;28mlen\u001b[39m(df_RF):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     24\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFor repro_phase=\u001b[39m\u001b[33m'\u001b[39m\u001b[33minc\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, df_MOM (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_MOM)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) and df_RF (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_RF)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) must have the same number of rows.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     25\u001b[39m         )\n\u001b[32m     27\u001b[39m     \u001b[38;5;66;03m# Join in order\u001b[39;00m\n\u001b[32m     28\u001b[39m     df_joined = pd.concat([df_MOM.reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m), df_RF.reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)], axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: For repro_phase='inc', df_MOM (2) and df_RF (0) must have the same number of rows."
     ]
    }
   ],
   "source": [
    "df_joined_inc = join_MOM_RFID_phase(df_Final_mom, subset_df, repro_phase=\"inc\")\n",
    "print(df_joined_inc.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "469f8a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- inside resolve_missing\n",
      "----- in resolve - burrow to find:  {'087'}\n",
      "38\n",
      "rfids found for  {'087'}\n",
      "----- in resolve - burrow to find:  {'235'}\n",
      "16\n",
      "rfids found for  {'235'}\n",
      "----- in resolve - burrow to find:  {'372'}\n",
      "7\n",
      "rfids found for  {'372'}\n",
      "----- in resolve - burrow to find:  {'377'}\n",
      "14\n",
      "rfids found for  {'377'}\n",
      "----- in resolve - burrow to find:  {'235'}\n",
      "0\n",
      "rfids found for  {'235'}\n",
      "----- in resolve - burrow to find:  {'382'}\n",
      "0\n",
      "rfids found for  {'382'}\n",
      "----- in resolve - burrow to find:  {'235'}\n",
      "0\n",
      "rfids found for  {'235'}\n",
      "----- in resolve - burrow to find:  {'372'}\n",
      "0\n",
      "rfids found for  {'372'}\n",
      "----- in resolve - burrow to find:  {'377'}\n",
      "0\n",
      "rfids found for  {'377'}\n",
      "----- in resolve - burrow to find:  {'380'}\n",
      "0\n",
      "rfids found for  {'380'}\n",
      "----- in resolve - burrow to find:  {'382'}\n",
      "0\n",
      "rfids found for  {'382'}\n",
      "----- in resolve - burrow to find:  {'372'}\n",
      "0\n",
      "rfids found for  {'372'}\n",
      "----- in resolve - burrow to find:  {'382'}\n",
      "0\n",
      "rfids found for  {'382'}\n",
      "----- in resolve - burrow to find:  {'377'}\n",
      "57\n",
      "rfids found for  {'377'}\n",
      "----- in resolve - burrow to find:  {'087'}\n",
      "0\n",
      "rfids found for  {'087'}\n",
      "----- in resolve - burrow to find:  {'235'}\n",
      "0\n",
      "rfids found for  {'235'}\n",
      "----- in resolve - burrow to find:  {'372'}\n",
      "0\n",
      "rfids found for  {'372'}\n",
      "----- in resolve - burrow to find:  {'377'}\n",
      "0\n",
      "rfids found for  {'377'}\n",
      "----- in resolve - burrow to find:  {'380'}\n",
      "0\n",
      "rfids found for  {'380'}\n",
      "----- in resolve - burrow to find:  {'372'}\n",
      "0\n",
      "rfids found for  {'372'}\n",
      "----- in resolve - burrow to find:  {'380'}\n",
      "0\n",
      "rfids found for  {'380'}\n",
      "----- in resolve - burrow to find:  {'087'}\n",
      "81\n",
      "rfids found for  {'087'}\n",
      "----- in resolve - burrow to find:  {'382'}\n",
      "0\n",
      "rfids found for  {'382'}\n",
      "----- in resolve - burrow to find:  {'372'}\n",
      "0\n",
      "rfids found for  {'372'}\n",
      "done resolving\n",
      "   Burrow                  MOM_File  MOM_Time Segment     Wt        RFID   N  \\\n",
      "0     087      DL_06_25_2025_87.TXT       NaN       3  51.72  0620000C7A  38   \n",
      "1     087      DL_06_25_2025_87.TXT       NaN       4  38.63  0620000DB6  38   \n",
      "2     235     DL_06_25_2025_235.TXT       NaN       3  50.17  0620000555  16   \n",
      "3     235     DL_06_25_2025_235.TXT       NaN       4  43.59  0620000555  16   \n",
      "4     372     DL_06_25_2025_372.TXT       NaN       3  53.86  0620000555   7   \n",
      "5     372     DL_06_25_2025_372.TXT       NaN      10  34.57  0620000555   7   \n",
      "6     377     DL_06_25_2025_377.TXT       NaN       1  47.23  0620000555  14   \n",
      "7     377     DL_06_25_2025_377.TXT       NaN       3  47.09  0620000555  14   \n",
      "8     235  DL_06_17-18_2025_235.TXT       NaN       3  54.73         NaN   0   \n",
      "9     235  DL_06_17-18_2025_235.TXT       NaN       4  53.39         NaN   0   \n",
      "10    235  DL_06_17-18_2025_235.TXT       NaN       3  55.69         NaN   0   \n",
      "11    235  DL_06_17-18_2025_235.TXT       NaN       4  43.06         NaN   0   \n",
      "12    382  DL_06_17-18_2025_382.TXT       NaN       3  50.37         NaN   0   \n",
      "13    382  DL_06_17-18_2025_382.TXT       NaN       4  48.06         NaN   0   \n",
      "14    382  DL_06_17-18_2025_382.TXT       NaN       1  50.19         NaN   0   \n",
      "15    235     DL_06_19_2025_235.TXT       NaN       3  51.76         NaN   0   \n",
      "16    372     DL_06_19_2025_372.TXT       NaN       3  51.44         NaN   0   \n",
      "17    377     DL_06_19_2025_377.TXT       NaN       3  51.52         NaN   0   \n",
      "18    377     DL_06_19_2025_377.TXT       NaN       4  46.89         NaN   0   \n",
      "19    380     DL_06_24_2025_380.TXT       NaN       4  56.99         NaN   0   \n",
      "\n",
      "     Rdr   Closest_RFID_Time                RF_File  \n",
      "0      1 2025-06-26 01:00:48   RF_06_25_2025_87.TXT  \n",
      "1      2 2025-06-26 01:09:48   RF_06_25_2025_87.TXT  \n",
      "2      1 2025-06-26 00:14:13  RF_06_25_2025_235.TXT  \n",
      "3      1 2025-06-26 00:14:13  RF_06_25_2025_235.TXT  \n",
      "4      1 2025-06-26 00:10:49  RF_06_25_2025_372.TXT  \n",
      "5      1 2025-06-26 00:10:49  RF_06_25_2025_372.TXT  \n",
      "6      1 2025-06-26 00:03:37  RF_06_25_2025_377.TXT  \n",
      "7      1 2025-06-26 00:03:37  RF_06_25_2025_377.TXT  \n",
      "8   <NA>                 NaT                    NaN  \n",
      "9   <NA>                 NaT                    NaN  \n",
      "10  <NA>                 NaT                    NaN  \n",
      "11  <NA>                 NaT                    NaN  \n",
      "12  <NA>                 NaT                    NaN  \n",
      "13  <NA>                 NaT                    NaN  \n",
      "14  <NA>                 NaT                    NaN  \n",
      "15  <NA>                 NaT                    NaN  \n",
      "16  <NA>                 NaT                    NaN  \n",
      "17  <NA>                 NaT                    NaN  \n",
      "18  <NA>                 NaT                    NaN  \n",
      "19  <NA>                 NaT                    NaN  \n"
     ]
    }
   ],
   "source": [
    "df_rfid = get_All_RFID_data(\"/Users/bobmauck/devel/Combo_App/Example_Data\")\n",
    "df_WtFiles = get_All_Mom_data(\"/Users/bobmauck/devel/Combo_App/Example_Data\")\n",
    "\n",
    "df_WtFiles['DateTime'] = pd.to_datetime(df_WtFiles['DateTime'], errors=\"coerce\")\n",
    "\n",
    "# filter rows with the placeholder datetime b/c can't be matched\n",
    "df_missing_time = df_WtFiles[df_WtFiles['DateTime'] == pd.Timestamp(\"2000-01-01 00:00:00\")].copy()\n",
    "\n",
    "# remove calibrations leaving valid\n",
    "valid_missing = remove_spurious_pairs(df_missing_time, \"Wt_Min_Slope\", low_val = 50, high_val = 75, tol  = 0.6) \n",
    "# print(valid_missing.head(10))\n",
    "\n",
    "if True:\n",
    "    df_r = resolve_missing_RFIDs(valid_missing, df_rfid)\n",
    "    print(\"done resolving\")\n",
    "    print(df_r.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e812969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_final_combo_MOM_RFIDold(df_WtFiles: pd.DataFrame,\n",
    "                               df_rfid: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build final combined MOM + RFID dataframe:\n",
    "      1. Run join_MOM_RFID2 to get df_MOM_with_counts\n",
    "      2. Find missing-time MOM rows, filter with remove_spurious_pairs,\n",
    "         and resolve them with resolve_missing_RFIDs\n",
    "      3. Append resolved rows back to df_MOM_with_counts\n",
    "      4. Sort final DataFrame by MOM_File then MOM_Time\n",
    "      5. Enforce final schema/column order\n",
    "      6. Add Matched flag (True if RFID match found, False otherwise)\n",
    "    \"\"\"\n",
    "\n",
    "    desired_cols = [\n",
    "        \"Burrow\", \"MOM_File\", \"MOM_Time\", \"Segment\", \"Wt\",\n",
    "        \"RFID\", \"N\", \"Rdr\", \"Closest_RFID_Time\", \"RF_File\", \"Matched\"\n",
    "    ]\n",
    "\n",
    "    # 1. Initial join\n",
    "    df_MOM_with_counts = join_MOM_RFID2(df_WtFiles, df_rfid, window=\"3min\")\n",
    "    df_MOM_with_counts[\"Matched\"] = False\n",
    "\n",
    "    # --- 🔑 Standardize naming ---\n",
    "    df_MOM_with_counts = df_MOM_with_counts.rename(\n",
    "        columns={\n",
    "            \"Wt_Min_Slope\": \"Wt\",\n",
    "            \"RFID_Time\": \"Closest_RFID_Time\",\n",
    "            \"Segmnt\": \"Segment\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # 2. Identify missing-time rows\n",
    "    df_WtFiles = df_WtFiles.copy()\n",
    "    df_WtFiles[\"DateTime\"] = pd.to_datetime(df_WtFiles[\"DateTime\"], errors=\"coerce\")\n",
    "    df_missing_time = df_WtFiles[\n",
    "        df_WtFiles[\"DateTime\"] == pd.Timestamp(\"2000-01-01 00:00:00\")\n",
    "    ].copy()\n",
    "\n",
    "    valid_missing = remove_spurious_pairs(\n",
    "        df_missing_time, \"Wt_Min_Slope\", low_val=50, high_val=75, tol=0.6\n",
    "    )\n",
    "\n",
    "    # print(\"valid missing:\")\n",
    "    # print(valid_missing.head(17))\n",
    "\n",
    "    # 3. Resolve missing rows\n",
    "    df_r = resolve_missing_RFIDs(valid_missing, df_rfid)\n",
    "\n",
    "    \n",
    "    if not df_r.empty:\n",
    "        print (\"df_r is empty\")\n",
    "        df_r = df_r.rename(\n",
    "            columns={\"Wt_Min_Slope\": \"Wt\", \"PIT_Time\": \"Closest_RFID_Time\"}\n",
    "        )\n",
    "        df_r[\"Matched\"] = df_r[\"RFID\"].notna()\n",
    "    else:\n",
    "        print(\"df_r is full\")\n",
    "        df_r = pd.DataFrame(columns=desired_cols)\n",
    "\n",
    "    # --- 🔑 Ensure both dfs have same schema ---\n",
    "    df_MOM_with_counts = df_MOM_with_counts.reindex(columns=desired_cols)\n",
    "    df_r = df_r.reindex(columns=desired_cols)\n",
    "\n",
    "    # 4. Combine\n",
    "    final_combo = pd.concat([df_MOM_with_counts, df_r], ignore_index=True)\n",
    "\n",
    "    # 5. Sort by MOM_File then MOM_Time\n",
    "    final_combo = final_combo.sort_values(\n",
    "        by=[\"MOM_File\", \"MOM_Time\"], ignore_index=True\n",
    "    )\n",
    "\n",
    "    # 6. Drop duplicates\n",
    "    final_combo = final_combo.drop_duplicates(\n",
    "        subset=[\"Burrow\", \"MOM_File\", \"Wt\"],\n",
    "        keep=\"first\",\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    return final_combo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "618a5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_burrow(val: str) -> str:\n",
    "    s = str(val)\n",
    "\n",
    "    # Remove file extension if present (.txt, .csv, any case)\n",
    "    for ext in (\".txt\", \".csv\"):\n",
    "        if s.lower().endswith(ext):\n",
    "            s = s[: -len(ext)]\n",
    "            break\n",
    "    # take the last 3 of what is left\n",
    "    s = s[-3:]\n",
    "\n",
    "    # deal with less than 3 digits\n",
    "    if s.startswith(\"_\"):       # e.g., \"_31\"\n",
    "        s = s[1:]               # drop the leading underscore → \"31\"\n",
    "    elif \"_\" in s:              # e.g., \"5_3\"\n",
    "        s = s.split(\"_\")[-1]    # take part after underscore → \"3\"\n",
    "\n",
    "    # Return only if it's digits and padded to 3 places\n",
    "    return s.zfill(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "d17e855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_missing_RFIDs(df_Missing_MOMs: pd.DataFrame,\n",
    "                          df_rfids: pd.DataFrame) -> pd.DataFrame:\n",
    "    if False: print(\"----------- inside resolve_missing\")\n",
    "\n",
    "    # accumulator list\n",
    "    resolved_chunks = []\n",
    "\n",
    "    # ensure PIT_DateTime is datetime in RFID file\n",
    "    df_all_rfids = df_rfids.copy()\n",
    "    df_all_rfids['PIT_DateTime'] = pd.to_datetime(df_all_rfids['PIT_DateTime'], errors=\"coerce\")\n",
    "\n",
    "    # unique MOM file names\n",
    "    unique_files = df_Missing_MOMs['MOM_File'].unique()\n",
    "    # if False:\n",
    "    #     print(\"unique files:\")\n",
    "    #     print(unique_files[:10])\n",
    "\n",
    "    for mom_file in unique_files:\n",
    "    \n",
    "        # subset mom records for this file\n",
    "        mom_temp = df_Missing_MOMs[df_Missing_MOMs['MOM_File'] == mom_file].copy()\n",
    "        if mom_temp.empty:\n",
    "            continue\n",
    "\n",
    "        # get focal date string from MOM_File (e.g., \"DL_06_25_2025_87.TXT\")\n",
    "        my_Day_str = mom_file[3:13]\n",
    "        focal_date = pd.to_datetime(my_Day_str, format=\"%m_%d_%Y\", errors=\"coerce\")\n",
    "\n",
    "        # time window: 20:00 same day → 07:00 next day\n",
    "        start = focal_date + pd.Timedelta(hours=20)\n",
    "        end   = focal_date + pd.Timedelta(days=1, hours=7)\n",
    "        if False:\n",
    "            print(\"start and end time:\")\n",
    "            print(start)\n",
    "            print(end)\n",
    "\n",
    "        # Burrow for these MOM records\n",
    "        my_burr = mom_temp['Burrow'].iloc[0]\n",
    "        if False: \n",
    "            print(\"----- in resolve - burrow to find: \", {my_burr})\n",
    "        #print(my_burr)\n",
    "        # my_burr = clean_burrow(val: str)\n",
    "        # if False: print(f\"N RFIDs: {len(df_rfids)}\")\n",
    "\n",
    "        # candidate RFID records\n",
    "        rfid_temp = df_all_rfids[\n",
    "            (df_all_rfids['Burrow'] == my_burr) &\n",
    "            (df_all_rfids['PIT_DateTime'] > start) &\n",
    "            (df_all_rfids['PIT_DateTime'] < end)\n",
    "        ].copy()\n",
    "\n",
    "        n_found = len(rfid_temp)\n",
    "        if False: # n_found > 0: \n",
    "            print(n_found)\n",
    "            print(\"rfids found for \", {my_burr})\n",
    "        # add column N = number of candidate RFID records\n",
    "        rfid_temp[\"N\"] = n_found\n",
    "\n",
    "        # keep earliest PIT record per PIT_ID\n",
    "        rfid_temp = earliest_per_pit(rfid_temp)\n",
    "\n",
    "        n_found2 = len(rfid_temp)\n",
    "        if False: # n_found > 0: \n",
    "            print(\"rfids after earliest pit\")\n",
    "            print(n_found2)\n",
    "            \n",
    "\n",
    "        if rfid_temp.empty:\n",
    "            if False: \n",
    "                print(\"Empty rfid_temp\")\n",
    "            # Add placeholder RFID columns — but MOM_Time stays as in mom_temp\n",
    "            mom_temp = mom_temp.assign(\n",
    "                RFID=pd.NA,\n",
    "                N=0,  # explicitly mark no RFID found\n",
    "                Rdr=pd.NA,\n",
    "                Closest_RFID_Time=pd.NaT,\n",
    "                RF_File=pd.NA\n",
    "            )\n",
    "            # if False: print(f\"no RFID found for {my_Day_str}_{my_burr}\")\n",
    "\n",
    "        else:\n",
    "            if False: \n",
    "                print(\"Got a valid rfid_temp\")\n",
    "            # Select and rename RFID columns to match desired schema\n",
    "            rfid_temp = rfid_temp.rename(columns={\n",
    "                \"PIT_ID\": \"RFID\",\n",
    "                \"PIT_DateTime\": \"Closest_RFID_Time\",\n",
    "                \"RF_File\": \"RF_File\",\n",
    "                \"Rdr\": \"Rdr\"\n",
    "            })[[\"RFID\", \"N\", \"Rdr\", \"Closest_RFID_Time\", \"RF_File\"]]\n",
    "\n",
    "            if len(mom_temp) == len(rfid_temp):\n",
    "                mom_temp = pd.concat([mom_temp.reset_index(drop=True),\n",
    "                                      rfid_temp.reset_index(drop=True)], axis=1)\n",
    "                if False:\n",
    "                    print(\"printing 1:1 ratio outcome:\")\n",
    "                    print(mom_temp)\n",
    "\n",
    "            elif len(mom_temp) > 1 and len(rfid_temp) == 1:\n",
    "                # Repeat RFID row to match length of mom_temp\n",
    "                rfid_repeated = pd.concat([rfid_temp] * len(mom_temp), ignore_index=True)\n",
    "                mom_temp = pd.concat([mom_temp.reset_index(drop=True),\n",
    "                                      rfid_repeated.reset_index(drop=True)], axis=1)\n",
    "                if False:\n",
    "                    print(\"printing 1:many outcome:\")\n",
    "                    print(mom_temp)\n",
    "\n",
    "            else:\n",
    "                # fallback: MOM row only, empty RFID fields\n",
    "                if False:\n",
    "                    print(\"bad ratio save empty:\")\n",
    "                    print(mom_temp)\n",
    "\n",
    "                mom_temp = mom_temp.assign(\n",
    "                    RFID=pd.NA,\n",
    "                    N=len(rfid_temp),\n",
    "                    Rdr=pd.NA,\n",
    "                    Closest_RFID_Time=pd.NaT,\n",
    "                    RF_File=pd.NA\n",
    "                )\n",
    "\n",
    "        # 🔑 MOM_Time is never touched or recalculated — original value is preserved\n",
    "        resolved_chunks.append(mom_temp)\n",
    "        if False: print(\"Records in reserved_chunks: \", len(resolved_chunks), my_burr)\n",
    "\n",
    "\n",
    "    # collapse all results into a single DataFrame\n",
    "    if len(resolved_chunks) == 0:\n",
    "        print(\"NO!!! Empty resolved\")\n",
    "        df_resolved_moms = pd.DataFrame(columns=[\n",
    "            \"Burrow\", \"MOM_File\", \"MOM_Time\", \"Segment\", \"Wt_Min_Slope\",\n",
    "            \"RFID\", \"N\", \"Rdr\", \"Closest_RFID_Time\", \"RF_File\"\n",
    "        ])\n",
    "    else:\n",
    "        \n",
    "        df_resolved_moms = pd.concat(resolved_chunks, ignore_index=True)\n",
    "        if False:\n",
    "            print(\"Chunks are full\")\n",
    "            print(\"resolved moms ready to go, here's head()\")\n",
    "            print(df_resolved_moms.head(25))\n",
    "      \n",
    "\n",
    "    # 🔑 Rename Wt_Min_Slope → Wt\n",
    "    if \"Wt_Min_Slope\" in df_resolved_moms.columns:\n",
    "        df_resolved_moms = df_resolved_moms.rename(columns={\"Wt_Min_Slope\": \"Wt\"})\n",
    "\n",
    "    # enforce final schema & column order\n",
    "    desired_cols = [\"Burrow\", \"MOM_File\", \"MOM_Time\", \"Segment\", \"Wt\",\n",
    "                    \"RFID\", \"N\", \"Rdr\", \"Closest_RFID_Time\", \"RF_File\"]\n",
    "    df_resolved_moms = df_resolved_moms.reindex(columns=desired_cols)\n",
    "\n",
    "    if False:\n",
    "        print(\"RETURN for df_resolved_moms\")\n",
    "        print(df_resolved_moms.head(20))\n",
    "\n",
    "    return df_resolved_moms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "42011b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_missing_RFIDs_DoALL(df_Missing_MOMs: pd.DataFrame,\n",
    "                          df_rfids: pd.DataFrame) -> pd.DataFrame:\n",
    "    if False: print(\"----------- inside resolve_missing\")\n",
    "\n",
    "    resolved_chunks = []\n",
    "\n",
    "    # ensure PIT_DateTime is datetime in RFID file\n",
    "    df_all_rfids = df_rfids.copy()\n",
    "    df_all_rfids['PIT_DateTime'] = pd.to_datetime(df_all_rfids['PIT_DateTime'], errors=\"coerce\")\n",
    "\n",
    "    # iterate through every MOM row\n",
    "    for _, mom_row in df_Missing_MOMs.iterrows():\n",
    "        mom_temp = mom_row.to_frame().T.copy()  # make it a DataFrame\n",
    "\n",
    "        # get focal date string from MOM_File (e.g., \"DL_06_25_2025_87.TXT\")\n",
    "        mom_file = mom_row[\"MOM_File\"]\n",
    "        my_Day_str = mom_file[3:13]\n",
    "        focal_date = pd.to_datetime(my_Day_str, format=\"%m_%d_%Y\", errors=\"coerce\")\n",
    "\n",
    "        # time window: 20:00 same day → 07:00 next day\n",
    "        start = focal_date + pd.Timedelta(hours=20)\n",
    "        end   = focal_date + pd.Timedelta(days=1, hours=7)\n",
    "\n",
    "        # Burrow for this MOM record\n",
    "        my_burr = mom_row[\"Burrow\"]\n",
    "\n",
    "        # candidate RFID records\n",
    "        rfid_temp = df_all_rfids[\n",
    "            (df_all_rfids[\"Burrow\"] == my_burr) &\n",
    "            (df_all_rfids[\"PIT_DateTime\"] > start) &\n",
    "            (df_all_rfids[\"PIT_DateTime\"] < end)\n",
    "        ].copy()\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        n_found = len(rfid_temp)\n",
    "\n",
    "        if my_burr == \"087\":\n",
    "            print(\"Burr 087:\")\n",
    "            print(\"df record found: \", n_found)\n",
    "\n",
    "\n",
    "        if rfid_temp.empty:\n",
    "            if my_burr == \"087\":\n",
    "                print(\"empty for 87\")\n",
    "            # Add placeholder RFID columns\n",
    "            mom_temp = mom_temp.assign(\n",
    "                RFID=pd.NA,\n",
    "                N=0,\n",
    "                Rdr=pd.NA,\n",
    "                Closest_RFID_Time=pd.NaT,\n",
    "                RF_File=pd.NA\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # add count\n",
    "            if my_burr == \"087\":\n",
    "                print(\"has rfid info for 87\")\n",
    "\n",
    "            rfid_temp[\"N\"] = n_found\n",
    "\n",
    "            # keep earliest PIT record per PIT_ID\n",
    "            rfid_temp = earliest_per_pit(rfid_temp)\n",
    "            if my_burr == \"087\":\n",
    "                print(\"Here is rf_id_temp...\")\n",
    "                print(rfid_temp)\n",
    "\n",
    "            # Select and rename RFID columns to match schema\n",
    "            rfid_temp = rfid_temp.rename(columns={\n",
    "                \"PIT_ID\": \"RFID\",\n",
    "                \"PIT_DateTime\": \"Closest_RFID_Time\",\n",
    "                \"RF_File\": \"RF_File\",\n",
    "                \"Rdr\": \"Rdr\"\n",
    "            })[[\"RFID\", \"N\", \"Rdr\", \"Closest_RFID_Time\", \"RF_File\"]]\n",
    "\n",
    "            # if more than one RFID, just repeat or align\n",
    "            if len(rfid_temp) == 1:\n",
    "                rfid_repeated = pd.concat([rfid_temp] * len(mom_temp), ignore_index=True)\n",
    "                mom_temp = pd.concat([mom_temp.reset_index(drop=True),\n",
    "                                      rfid_repeated.reset_index(drop=True)], axis=1)\n",
    "            elif len(mom_temp) == len(rfid_temp):\n",
    "                mom_temp = pd.concat([mom_temp.reset_index(drop=True),\n",
    "                                      rfid_temp.reset_index(drop=True)], axis=1)\n",
    "            else:\n",
    "                # mismatch fallback → just attach N and empty RFID info\n",
    "                mom_temp = mom_temp.assign(\n",
    "                    RFID=pd.NA,\n",
    "                    N=len(rfid_temp),\n",
    "                    Rdr=pd.NA,\n",
    "                    Closest_RFID_Time=pd.NaT,\n",
    "                    RF_File=pd.NA\n",
    "                )\n",
    "\n",
    "        resolved_chunks.append(mom_temp)\n",
    "\n",
    "    # collapse all results\n",
    "    if not resolved_chunks:\n",
    "        df_resolved_moms = pd.DataFrame(columns=[\n",
    "            \"Burrow\", \"MOM_File\", \"MOM_Time\", \"Segment\", \"Wt_Min_Slope\",\n",
    "            \"RFID\", \"N\", \"Rdr\", \"Closest_RFID_Time\", \"RF_File\"\n",
    "        ])\n",
    "    else:\n",
    "        df_resolved_moms = pd.concat(resolved_chunks, ignore_index=True)\n",
    "\n",
    "    # rename Wt_Min_Slope → Wt\n",
    "    if \"Wt_Min_Slope\" in df_resolved_moms.columns:\n",
    "        df_resolved_moms = df_resolved_moms.rename(columns={\"Wt_Min_Slope\": \"Wt\"})\n",
    "\n",
    "    # enforce schema\n",
    "    desired_cols = [\"Burrow\", \"MOM_File\", \"MOM_Time\", \"Segment\", \"Wt\",\n",
    "                    \"RFID\", \"N\", \"Rdr\", \"Closest_RFID_Time\", \"RF_File\"]\n",
    "    df_resolved_moms = df_resolved_moms.reindex(columns=desired_cols)\n",
    "\n",
    "    if False:\n",
    "        print(\"RETURN for df_resolved_moms\")\n",
    "        print(df_resolved_moms.head(20))\n",
    "\n",
    "    return df_resolved_moms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c1546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_final_combo_MOM_RFID(df_WtFiles: pd.DataFrame,\n",
    "                               df_rfid: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build final combined MOM + RFID dataframe:\n",
    "      1. Run join_MOM_RFID2 to get df_MOM_with_counts\n",
    "      2. Find missing-time MOM rows, filter with remove_spurious_pairs,\n",
    "         and resolve them with resolve_missing_RFIDs\n",
    "      3. Append resolved rows back to df_MOM_with_counts\n",
    "      4. Sort final DataFrame by MOM_File then MOM_Time\n",
    "      5. Enforce final schema/column order\n",
    "      6. Add Matched flag (True if RFID match found, False otherwise)\n",
    "    \"\"\"\n",
    "\n",
    "    desired_cols = [\n",
    "        \"Burrow\", \"MOM_File\", \"MOM_Time\", \"Wt\",\n",
    "        \"RFID\", \"N\", \"Rdr\", \"Closest_RFID_Time\", \"RF_File\", \"Matched\"\n",
    "    ]\n",
    "\n",
    "    # 1. Initial join\n",
    "    df_MOM_with_counts = join_MOM_RFID2(df_WtFiles, df_rfid, window=\"3min\")\n",
    "    df_MOM_with_counts[\"Matched\"] = False\n",
    "\n",
    "    # --- 🔑 Standardize naming ---\n",
    "    df_MOM_with_counts = df_MOM_with_counts.rename(\n",
    "        columns={\n",
    "            \"Wt_Min_Slope\": \"Wt\",\n",
    "            \"RFID_Time\": \"Closest_RFID_Time\",\n",
    "            \"Segmnt\": \"Segment\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # 2. Identify missing-time rows\n",
    "    df_WtFiles = df_WtFiles.copy()\n",
    "    df_WtFiles[\"DateTime\"] = pd.to_datetime(df_WtFiles[\"DateTime\"], errors=\"coerce\")\n",
    "\n",
    "    if True:\n",
    "        n_records_87Before = len(df_WtFiles[df_WtFiles[\"Burrow\"] == \"087\"])\n",
    "        print(\"Number of records with Burrow == '087':\", n_records_87Before)\n",
    "\n",
    "\n",
    "    df_missing_time = df_WtFiles[\n",
    "        df_WtFiles[\"DateTime\"] == pd.Timestamp(\"2000-01-01 00:00:00\")].copy()\n",
    "\n",
    "    #### --- CHANGE -- remove df_missing_time from df_WtFiles\n",
    "    df_WtFiles = df_WtFiles[df_WtFiles[\"DateTime\"] != pd.Timestamp(\"2000-01-01 00:00:00\")].copy()\n",
    "\n",
    "\n",
    "    if True:\n",
    "        n_records_87after = len(df_missing_time[df_missing_time[\"Burrow\"] == \"087\"])\n",
    "        print(\"Number of records '087' with missing time:\", n_records_87after)\n",
    "\n",
    "    if True: \n",
    "        print(\"df_missing_time #recs \", len(df_missing_time))\n",
    "        # print(df_missing_time.head(10))\n",
    "\n",
    "    valid_missing = remove_spurious_pairs(\n",
    "        df_missing_time, \"Wt_Min_Slope\", low_val=50, high_val=75, tol=0.6\n",
    "    )\n",
    "\n",
    "    if True:\n",
    "        n_records_87after = len(df_missing_time[df_missing_time[\"Burrow\"] == \"087\"])\n",
    "        print(\"Number of records '087' after removing spurious:\", n_records_87after)\n",
    "\n",
    "    # 3. Resolve missing rows\n",
    "    df_r = resolve_missing_RFIDs(valid_missing, df_rfid) #----- this is Correct - right number/and linked\n",
    "\n",
    "    if True:\n",
    "        n_records_87after = len(df_r[df_r[\"Burrow\"] == \"087\"])\n",
    "        print(\"Number of records '087' after removing resolve_missing_RFIDS:\", n_records_87after)\n",
    "        records_087 = df_r[df_r[\"Burrow\"] == \"087\"]\n",
    "        print(records_087)\n",
    "        print(\"--------\")\n",
    "\n",
    "\n",
    "    if False: \n",
    "        print(\"df_rhead\")\n",
    "        print(df_r.head(5))\n",
    "    \n",
    "    if not df_r.empty:\n",
    "        if False: print (\"df_r is NOT empty\") \n",
    "        df_r = df_r.rename(\n",
    "            columns={\"Wt_Min_Slope\": \"Wt\", \"PIT_Time\": \"Closest_RFID_Time\"}\n",
    "        )\n",
    "        df_r[\"Matched\"] = df_r[\"RFID\"].notna()\n",
    "    else:\n",
    "        if False: print(\"df_r is full\")\n",
    "        df_r = pd.DataFrame(columns=desired_cols)\n",
    "\n",
    "    # losing something here lost df_r values \n",
    "\n",
    "    # --- 🔑 Ensure both dfs have same schema ---\n",
    "    df_MOM_with_counts = df_MOM_with_counts.reindex(columns=desired_cols)\n",
    "    ## remove all bad dates becaues they are restored with df_r\n",
    "\n",
    "\n",
    "    df_r = df_r.reindex(columns=desired_cols)\n",
    "\n",
    "    if False:\n",
    "        print(\"--- head for MOMs and RFID before concat\")\n",
    "        print(df_MOM_with_counts.head(3))\n",
    "        print(df_r.head(3))\n",
    "    # 4. Combine - this is the problem. we want to keep the empty MOM RTCs, but they are overriding the resolved. Resolved should have them all\n",
    "    #               and the df_MOM should have none. Then when combined, we are fine\n",
    "    #               need ot change resolve because it only deals with unique values, doesn't return full list of all records to be done\n",
    "    #               OR, we need to eliminate it somewhere else\n",
    "    # final_combo = pd.concat([df_MOM_with_counts, df_r], ignore_index=True)\n",
    "    final_combo = pd.concat([df_MOM_with_counts, df_r], ignore_index=True)\n",
    "    if False:\n",
    "        print(\"--- final combo\")\n",
    "        print(final_combo.head(30))\n",
    "\n",
    "    if True:\n",
    "        n_records_87after = len(final_combo[final_combo[\"Burrow\"] == \"087\"])\n",
    "        print(\"Number of records '087' after in final COMBO: \", n_records_87after)\n",
    "        records_087 = final_combo[final_combo[\"Burrow\"] == \"087\"]\n",
    "        print(records_087)\n",
    "        print(\"--------\")\n",
    "\n",
    "    # 5. Sort by MOM_File then MOM_Time\n",
    "    final_combo = final_combo.sort_values(\n",
    "        by=[\"MOM_File\", \"MOM_Time\"], ignore_index=True\n",
    "    )\n",
    "\n",
    "    # 6. Drop duplicates\n",
    "    final_combo = final_combo.drop_duplicates(\n",
    "        subset=[\"Burrow\", \"MOM_File\", \"Wt\"],\n",
    "        keep=\"first\",\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    return final_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "e70d5308",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xp/8z1j89ns7md79c4g_c7r5g6m0000gn/T/ipykernel_1393/2577505564.py:169: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  out = pd.concat(pieces, ignore_index=False).sort_index(kind=\"mergesort\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records with Burrow == '087': 6\n",
      "Number of records '087' with missing time: 6\n",
      "df_missing_time #recs  48\n",
      "Number of records '087' after removing spurious: 6\n",
      "Number of records '087' after removing resolve_missing_RFIDS: 6\n",
      "   Burrow                 MOM_File  MOM_Time Segment     Wt        RFID   N  \\\n",
      "0     087     DL_06_25_2025_87.TXT       NaN       3  51.72  0620000C7A  38   \n",
      "1     087     DL_06_25_2025_87.TXT       NaN       4  38.63  0620000DB6  38   \n",
      "29    087  DL_06_21-22_2025_87.TXT       NaN       4  46.70         NaN   0   \n",
      "30    087  DL_06_21-22_2025_87.TXT       NaN       5  39.28         NaN   0   \n",
      "42    087     DL_06_16_2025_87.TXT       NaN       3  51.63  0620000C7A  81   \n",
      "43    087     DL_06_16_2025_87.TXT       NaN       4  44.95  0620000DB6  81   \n",
      "\n",
      "     Rdr   Closest_RFID_Time               RF_File  \n",
      "0      1 2025-06-26 01:00:48  RF_06_25_2025_87.TXT  \n",
      "1      2 2025-06-26 01:09:48  RF_06_25_2025_87.TXT  \n",
      "29  <NA>                 NaT                   NaN  \n",
      "30  <NA>                 NaT                   NaN  \n",
      "42     1 2025-06-17 01:13:59  RF_06_18_2025_87.TXT  \n",
      "43     1 2025-06-17 01:40:09  RF_06_18_2025_87.TXT  \n",
      "--------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'DateTime'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'DateTime'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[424]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      6\u001b[39m df_WtFiles_clean = remove_spurious_pairs(df_WtFiles, \u001b[33m\"\u001b[39m\u001b[33mWt_Min_Slope\u001b[39m\u001b[33m\"\u001b[39m, low_val = \u001b[32m50\u001b[39m, high_val = \u001b[32m75\u001b[39m, tol  = \u001b[32m0.6\u001b[39m) \n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# df_WtFiles_clean = remove_spurious_pairs(df_WtFiles, \"Wt\", low_val = 50, high_val = 75, tol  = 0.6) \u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m#########\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m#   This works. should work inside the app as is. Need to do above to get its parameters\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#   in the app, those will be done via GUI\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m####\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m df_finale= \u001b[43mbuild_final_combo_MOM_RFID\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_WtFiles_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_rfid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m df_finale = df_finale.sort_values([\u001b[33m\"\u001b[39m\u001b[33mBurrow\u001b[39m\u001b[33m\"\u001b[39m], kind=\u001b[33m\"\u001b[39m\u001b[33mmergesort\u001b[39m\u001b[33m\"\u001b[39m).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_finale.head(\u001b[32m17\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[423]\u001b[39m\u001b[32m, line 88\u001b[39m, in \u001b[36mbuild_final_combo_MOM_RFID\u001b[39m\u001b[34m(df_WtFiles, df_rfid)\u001b[39m\n\u001b[32m     84\u001b[39m     df_r = pd.DataFrame(columns=desired_cols)\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# losing something here lost df_r values \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m df_MOM_with_counts = df_MOM_with_counts[\u001b[43mdf_MOM_with_counts\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDateTime\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m != pd.Timestamp(\u001b[33m\"\u001b[39m\u001b[33m2000-01-01 00:00:00\u001b[39m\u001b[33m\"\u001b[39m)].copy()\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# --- 🔑 Ensure both dfs have same schema ---\u001b[39;00m\n\u001b[32m     91\u001b[39m df_MOM_with_counts = df_MOM_with_counts.reindex(columns=desired_cols)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'DateTime'"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "df_rfid = get_All_RFID_data(\"/Users/bobmauck/devel/Combo_App/Example_Data\")\n",
    "df_WtFiles = get_All_Mom_data(\"/Users/bobmauck/devel/Combo_App/Example_Data\")\n",
    "\n",
    "df_WtFiles['DateTime'] = pd.to_datetime(df_WtFiles['DateTime'], errors=\"coerce\")\n",
    "\n",
    "df_WtFiles_clean = remove_spurious_pairs(df_WtFiles, \"Wt_Min_Slope\", low_val = 50, high_val = 75, tol  = 0.6) \n",
    "# df_WtFiles_clean = remove_spurious_pairs(df_WtFiles, \"Wt\", low_val = 50, high_val = 75, tol  = 0.6) \n",
    "#########\n",
    "#   This works. should work inside the app as is. Need to do above to get its parameters\n",
    "#   in the app, those will be done via GUI\n",
    "####\n",
    "df_finale= build_final_combo_MOM_RFID(df_WtFiles_clean, df_rfid)\n",
    "df_finale = df_finale.sort_values([\"Burrow\"], kind=\"mergesort\").reset_index(drop=True)\n",
    "print(df_finale.head(17))\n",
    "df_finale.to_csv(\"df_Final_JoinedWORKS2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
